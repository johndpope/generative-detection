[rank: 0] Global seed set to 23
[rank: 1] Global seed set to 23
[rank: 2] Global seed set to 23
[rank: 3] Global seed set to 23
INFO:root:Options: {
  "transformers_cache": ".cache/transformers_cache",
  "torch_home": ".cache/torch_home",
  "logging_level": "INFO",
  "name": "od_vae_test_1gpu",
  "resume": "",
  "base": [
    "configs/autoencoder/pose/jo_autoencoder_kl_16x16x16.yaml"
  ],
  "train": true,
  "no_test": false,
  "project": null,
  "debug": false,
  "seed": 23,
  "postfix": "",
  "logdir": "logs",
  "scale_lr": true,
  "logger": true,
  "enable_checkpointing": true,
  "default_root_dir": null,
  "gradient_clip_val": null,
  "gradient_clip_algorithm": null,
  "num_nodes": 1,
  "num_processes": null,
  "devices": "4",
  "gpus": null,
  "auto_select_gpus": null,
  "tpu_cores": null,
  "ipus": null,
  "enable_progress_bar": true,
  "overfit_batches": 0.0,
  "track_grad_norm": -1,
  "check_val_every_n_epoch": 1,
  "fast_dev_run": false,
  "accumulate_grad_batches": null,
  "max_epochs": null,
  "min_epochs": null,
  "max_steps": -1,
  "min_steps": null,
  "max_time": null,
  "limit_train_batches": null,
  "limit_val_batches": null,
  "limit_test_batches": null,
  "limit_predict_batches": null,
  "val_check_interval": null,
  "log_every_n_steps": 50,
  "accelerator": null,
  "strategy": null,
  "sync_batchnorm": false,
  "precision": 32,
  "enable_model_summary": true,
  "num_sanity_val_steps": 2,
  "resume_from_checkpoint": null,
  "profiler": null,
  "benchmark": null,
  "reload_dataloaders_every_n_epochs": 0,
  "auto_lr_find": false,
  "replace_sampler_ddp": true,
  "detect_anomaly": false,
  "auto_scale_batch_size": false,
  "plugins": null,
  "amp_backend": null,
  "amp_level": null,
  "move_metrics_to_cpu": false,
  "multiple_trainloader_mode": "max_size_cycle",
  "inference_mode": true
}
INFO:root:Options: {
  "transformers_cache": ".cache/transformers_cache",
  "torch_home": ".cache/torch_home",
  "logging_level": "INFO",
  "name": "od_vae_test_1gpu",
  "resume": "",
  "base": [
    "configs/autoencoder/pose/jo_autoencoder_kl_16x16x16.yaml"
  ],
  "train": true,
  "no_test": false,
  "project": null,
  "debug": false,
  "seed": 23,
  "postfix": "",
  "logdir": "logs",
  "scale_lr": true,
  "logger": true,
  "enable_checkpointing": true,
  "default_root_dir": null,
  "gradient_clip_val": null,
  "gradient_clip_algorithm": null,
  "num_nodes": 1,
  "num_processes": null,
  "devices": "4",
  "gpus": null,
  "auto_select_gpus": null,
  "tpu_cores": null,
  "ipus": null,
  "enable_progress_bar": true,
  "overfit_batches": 0.0,
  "track_grad_norm": -1,
  "check_val_every_n_epoch": 1,
  "fast_dev_run": false,
  "accumulate_grad_batches": null,
  "max_epochs": null,
  "min_epochs": null,
  "max_steps": -1,
  "min_steps": null,
  "max_time": null,
  "limit_train_batches": null,
  "limit_val_batches": null,
  "limit_test_batches": null,
  "limit_predict_batches": null,
  "val_check_interval": null,
  "log_every_n_steps": 50,
  "accelerator": null,
  "strategy": null,
  "sync_batchnorm": false,
  "precision": 32,
  "enable_model_summary": true,
  "num_sanity_val_steps": 2,
  "resume_from_checkpoint": null,
  "profiler": null,
  "benchmark": null,
  "reload_dataloaders_every_n_epochs": 0,
  "auto_lr_find": false,
  "replace_sampler_ddp": true,
  "detect_anomaly": false,
  "auto_scale_batch_size": false,
  "plugins": null,
  "amp_backend": null,
  "amp_level": null,
  "move_metrics_to_cpu": false,
  "multiple_trainloader_mode": "max_size_cycle",
  "inference_mode": true
}
INFO:root:Options: {
  "transformers_cache": ".cache/transformers_cache",
  "torch_home": ".cache/torch_home",
  "logging_level": "INFO",
  "name": "od_vae_test_1gpu",
  "resume": "",
  "base": [
    "configs/autoencoder/pose/jo_autoencoder_kl_16x16x16.yaml"
  ],
  "train": true,
  "no_test": false,
  "project": null,
  "debug": false,
  "seed": 23,
  "postfix": "",
  "logdir": "logs",
  "scale_lr": true,
  "logger": true,
  "enable_checkpointing": true,
  "default_root_dir": null,
  "gradient_clip_val": null,
  "gradient_clip_algorithm": null,
  "num_nodes": 1,
  "num_processes": null,
  "devices": "4",
  "gpus": null,
  "auto_select_gpus": null,
  "tpu_cores": null,
  "ipus": null,
  "enable_progress_bar": true,
  "overfit_batches": 0.0,
  "track_grad_norm": -1,
  "check_val_every_n_epoch": 1,
  "fast_dev_run": false,
  "accumulate_grad_batches": null,
  "max_epochs": null,
  "min_epochs": null,
  "max_steps": -1,
  "min_steps": null,
  "max_time": null,
  "limit_train_batches": null,
  "limit_val_batches": null,
  "limit_test_batches": null,
  "limit_predict_batches": null,
  "val_check_interval": null,
  "log_every_n_steps": 50,
  "accelerator": null,
  "strategy": null,
  "sync_batchnorm": false,
  "precision": 32,
  "enable_model_summary": true,
  "num_sanity_val_steps": 2,
  "resume_from_checkpoint": null,
  "profiler": null,
  "benchmark": null,
  "reload_dataloaders_every_n_epochs": 0,
  "auto_lr_find": false,
  "replace_sampler_ddp": true,
  "detect_anomaly": false,
  "auto_scale_batch_size": false,
  "plugins": null,
  "amp_backend": null,
  "amp_level": null,
  "move_metrics_to_cpu": false,
  "multiple_trainloader_mode": "max_size_cycle",
  "inference_mode": true
}
INFO:root:Options: {
  "transformers_cache": ".cache/transformers_cache",
  "torch_home": ".cache/torch_home",
  "logging_level": "INFO",
  "name": "od_vae_test_1gpu",
  "resume": "",
  "base": [
    "configs/autoencoder/pose/jo_autoencoder_kl_16x16x16.yaml"
  ],
  "train": true,
  "no_test": false,
  "project": null,
  "debug": false,
  "seed": 23,
  "postfix": "",
  "logdir": "logs",
  "scale_lr": true,
  "logger": true,
  "enable_checkpointing": true,
  "default_root_dir": null,
  "gradient_clip_val": null,
  "gradient_clip_algorithm": null,
  "num_nodes": 1,
  "num_processes": null,
  "devices": "4",
  "gpus": null,
  "auto_select_gpus": null,
  "tpu_cores": null,
  "ipus": null,
  "enable_progress_bar": true,
  "overfit_batches": 0.0,
  "track_grad_norm": -1,
  "check_val_every_n_epoch": 1,
  "fast_dev_run": false,
  "accumulate_grad_batches": null,
  "max_epochs": null,
  "min_epochs": null,
  "max_steps": -1,
  "min_steps": null,
  "max_time": null,
  "limit_train_batches": null,
  "limit_val_batches": null,
  "limit_test_batches": null,
  "limit_predict_batches": null,
  "val_check_interval": null,
  "log_every_n_steps": 50,
  "accelerator": null,
  "strategy": null,
  "sync_batchnorm": false,
  "precision": 32,
  "enable_model_summary": true,
  "num_sanity_val_steps": 2,
  "resume_from_checkpoint": null,
  "profiler": null,
  "benchmark": null,
  "reload_dataloaders_every_n_epochs": 0,
  "auto_lr_find": false,
  "replace_sampler_ddp": true,
  "detect_anomaly": false,
  "auto_scale_batch_size": false,
  "plugins": null,
  "amp_backend": null,
  "amp_level": null,
  "move_metrics_to_cpu": false,
  "multiple_trainloader_mode": "max_size_cycle",
  "inference_mode": true
}
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/modules/losses/contperceptual.py:104: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  parameters = torch.tensor(parameters)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/modules/losses/contperceptual.py:104: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  parameters = torch.tensor(parameters)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/modules/losses/contperceptual.py:104: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  parameters = torch.tensor(parameters)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/modules/losses/contperceptual.py:104: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  parameters = torch.tensor(parameters)
INFO:root:Monitoring val/rec_loss as checkpoint metric.
INFO:root:Using ModelCheckpoint with {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2024-05-17T17-27-52_od_vae_test_1gpu/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/rec_loss', 'save_top_k': 3}}
INFO:root:Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2024-05-17T17-27-52_od_vae_test_1gpu/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/rec_loss', 'save_top_k': 3}}
INFO:root:Monitoring val/rec_loss as checkpoint metric.
INFO:root:Using ModelCheckpoint with {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2024-05-17T17-27-52_od_vae_test_1gpu/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/rec_loss', 'save_top_k': 3}}
INFO:root:Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2024-05-17T17-27-52_od_vae_test_1gpu/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/rec_loss', 'save_top_k': 3}}
INFO:root:Monitoring val/rec_loss as checkpoint metric.
INFO:root:Using ModelCheckpoint with {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2024-05-17T17-27-52_od_vae_test_1gpu/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/rec_loss', 'save_top_k': 3}}
INFO:root:Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2024-05-17T17-27-52_od_vae_test_1gpu/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/rec_loss', 'save_top_k': 3}}
wandb: Currently logged in as: ostjul (ostjul13). Use `wandb login --relogin` to force relogin
wandb: WARNING Path logs/2024-05-17T17-27-52_od_vae_test_1gpu/wandb/ wasn't writable, using system temp directory.
wandb: WARNING Path logs/2024-05-17T17-27-52_od_vae_test_1gpu/wandb/ wasn't writable, using system temp directory
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 16, 4, 4) = 256 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth
Loaded dataset stats:
{'t1': tensor([ 7.6356e-09, -1.8421e+01]), 't2': tensor([ 2.9980e-09, -1.8421e+01]), 't3': tensor([ 0.2343, -2.6865]), 'v3': tensor([0.1066, 1.1088]), 'l': tensor([ 2.6797, -2.4134]), 'h': tensor([ 1.7426, -2.7465]), 'w': tensor([ 1.1360, -4.0951]), 'yaw': tensor([0.1067, 1.1239]), 'fill_factor': tensor([ 0.4094, -3.2034])}
05/17 17:27:58 - mmengine - INFO - ------------------------------
05/17 17:27:58 - mmengine - INFO - The length of training dataset: 1938
05/17 17:27:58 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 16, 4, 4) = 256 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth
Loaded dataset stats:
{'t1': tensor([ 7.6356e-09, -1.8421e+01]), 't2': tensor([ 2.9980e-09, -1.8421e+01]), 't3': tensor([ 0.2343, -2.6865]), 'v3': tensor([0.1066, 1.1088]), 'l': tensor([ 2.6797, -2.4134]), 'h': tensor([ 1.7426, -2.7465]), 'w': tensor([ 1.1360, -4.0951]), 'yaw': tensor([0.1067, 1.1239]), 'fill_factor': tensor([ 0.4094, -3.2034])}
05/17 17:27:58 - mmengine - INFO - ------------------------------
05/17 17:27:58 - mmengine - INFO - The length of training dataset: 1938
05/17 17:27:58 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 16, 4, 4) = 256 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth
Loaded dataset stats:
{'t1': tensor([ 7.6356e-09, -1.8421e+01]), 't2': tensor([ 2.9980e-09, -1.8421e+01]), 't3': tensor([ 0.2343, -2.6865]), 'v3': tensor([0.1066, 1.1088]), 'l': tensor([ 2.6797, -2.4134]), 'h': tensor([ 1.7426, -2.7465]), 'w': tensor([ 1.1360, -4.0951]), 'yaw': tensor([0.1067, 1.1239]), 'fill_factor': tensor([ 0.4094, -3.2034])}
05/17 17:27:58 - mmengine - INFO - ------------------------------
05/17 17:27:58 - mmengine - INFO - The length of training dataset: 1938
05/17 17:27:58 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:27:59 - mmengine - INFO - ------------------------------
05/17 17:27:59 - mmengine - INFO - The length of training dataset: 486
05/17 17:27:59 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:27:59 - mmengine - INFO - ------------------------------
05/17 17:27:59 - mmengine - INFO - The length of training dataset: 486
05/17 17:27:59 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:27:59 - mmengine - INFO - ------------------------------
05/17 17:27:59 - mmengine - INFO - The length of training dataset: 486
05/17 17:27:59 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:28:00 - mmengine - INFO - ------------------------------
05/17 17:28:00 - mmengine - INFO - The length of training dataset: 1938
05/17 17:28:00 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:28:00 - mmengine - INFO - ------------------------------
05/17 17:28:00 - mmengine - INFO - The length of training dataset: 1938
05/17 17:28:00 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:28:00 - mmengine - INFO - ------------------------------
05/17 17:28:00 - mmengine - INFO - The length of training dataset: 1938
05/17 17:28:00 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:28:00 - mmengine - INFO - ------------------------------
05/17 17:28:00 - mmengine - INFO - The length of training dataset: 486
05/17 17:28:00 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
INFO:root:#### Data #####
INFO:root:train, WrappedDataset, 1938
INFO:root:validation, WrappedDataset, 486
INFO:root:accumulate_grad_batches = 1
INFO:root:Setting learning rate to 1.80e-05 = 1 (accumulate_grad_batches) * 1 (num_gpus) * 4 (batchsize) * 4.50e-06 (base_lr)
[rank: 2] Global seed set to 23
05/17 17:28:00 - mmengine - INFO - ------------------------------
05/17 17:28:00 - mmengine - INFO - The length of training dataset: 486
05/17 17:28:00 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
INFO:root:#### Data #####
INFO:root:train, WrappedDataset, 1938
INFO:root:validation, WrappedDataset, 486
INFO:root:accumulate_grad_batches = 1
INFO:root:Setting learning rate to 1.80e-05 = 1 (accumulate_grad_batches) * 1 (num_gpus) * 4 (batchsize) * 4.50e-06 (base_lr)
[rank: 3] Global seed set to 23
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
05/17 17:28:00 - mmengine - INFO - ------------------------------
05/17 17:28:00 - mmengine - INFO - The length of training dataset: 486
05/17 17:28:00 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
INFO:root:#### Data #####
INFO:root:train, WrappedDataset, 1938
INFO:root:validation, WrappedDataset, 486
INFO:root:accumulate_grad_batches = 1
INFO:root:Setting learning rate to 1.80e-05 = 1 (accumulate_grad_batches) * 1 (num_gpus) * 4 (batchsize) * 4.50e-06 (base_lr)
[rank: 1] Global seed set to 23
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /tmp/wandb/run-20240517_172757-2024-05-17T17-27-52_od_vae_test_1gpu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 2024-05-17T17-27-52_od_vae_test_1gpu
wandb: ⭐️ View project at https://wandb.ai/ostjul13/lightning_logs
wandb: 🚀 View run at https://wandb.ai/ostjul13/lightning_logs/runs/2024-05-17T17-27-52_od_vae_test_1gpu
INFO:root:Monitoring val/rec_loss as checkpoint metric.
INFO:root:Using ModelCheckpoint with {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2024-05-17T17-27-52_od_vae_test_1gpu/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/rec_loss', 'save_top_k': 3}}
INFO:root:Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2024-05-17T17-27-52_od_vae_test_1gpu/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/rec_loss', 'save_top_k': 3}}
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 16, 4, 4) = 256 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth
Loaded dataset stats:
{'t1': tensor([ 7.6356e-09, -1.8421e+01]), 't2': tensor([ 2.9980e-09, -1.8421e+01]), 't3': tensor([ 0.2343, -2.6865]), 'v3': tensor([0.1066, 1.1088]), 'l': tensor([ 2.6797, -2.4134]), 'h': tensor([ 1.7426, -2.7465]), 'w': tensor([ 1.1360, -4.0951]), 'yaw': tensor([0.1067, 1.1239]), 'fill_factor': tensor([ 0.4094, -3.2034])}
05/17 17:28:05 - mmengine - INFO - ------------------------------
05/17 17:28:05 - mmengine - INFO - The length of training dataset: 1938
05/17 17:28:05 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:28:05 - mmengine - INFO - ------------------------------
05/17 17:28:05 - mmengine - INFO - The length of training dataset: 486
05/17 17:28:05 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:28:06 - mmengine - INFO - ------------------------------
05/17 17:28:06 - mmengine - INFO - The length of training dataset: 1938
05/17 17:28:06 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:28:06 - mmengine - INFO - ------------------------------
05/17 17:28:06 - mmengine - INFO - The length of training dataset: 486
05/17 17:28:06 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
INFO:root:#### Data #####
INFO:root:train, WrappedDataset, 1938
INFO:root:validation, WrappedDataset, 486
INFO:root:accumulate_grad_batches = 1
INFO:root:Setting learning rate to 1.80e-05 = 1 (accumulate_grad_batches) * 1 (num_gpus) * 4 (batchsize) * 4.50e-06 (base_lr)
05/17 17:28:07 - mmengine - INFO - ------------------------------
05/17 17:28:07 - mmengine - INFO - The length of training dataset: 1938
05/17 17:28:07 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:28:08 - mmengine - INFO - ------------------------------
05/17 17:28:08 - mmengine - INFO - The length of training dataset: 486
05/17 17:28:08 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
[rank: 0] Global seed set to 23
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 3
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 2
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 1
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0
INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
node209:731296:731296 [0] NCCL INFO Bootstrap : Using ens6f0np0:172.17.26.129<0>
node209:731296:731296 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node209:731296:731296 [0] NCCL INFO NET/IB : No device found.
node209:731296:731296 [0] NCCL INFO NET/Socket : Using [0]ens6f0np0:172.17.26.129<0>
node209:731296:731296 [0] NCCL INFO Using network Socket
NCCL version 2.10.3+cuda11.6
node209:731297:731297 [1] NCCL INFO Bootstrap : Using ens6f0np0:172.17.26.129<0>
node209:731298:731298 [2] NCCL INFO Bootstrap : Using ens6f0np0:172.17.26.129<0>
node209:731299:731299 [3] NCCL INFO Bootstrap : Using ens6f0np0:172.17.26.129<0>
node209:731298:731298 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node209:731297:731297 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node209:731299:731299 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node209:731298:731298 [2] NCCL INFO NET/IB : No device found.
node209:731299:731299 [3] NCCL INFO NET/IB : No device found.
node209:731297:731297 [1] NCCL INFO NET/IB : No device found.
node209:731297:731297 [1] NCCL INFO NET/Socket : Using [0]ens6f0np0:172.17.26.129<0>
node209:731297:731297 [1] NCCL INFO Using network Socket
node209:731298:731298 [2] NCCL INFO NET/Socket : Using [0]ens6f0np0:172.17.26.129<0>
node209:731298:731298 [2] NCCL INFO Using network Socket
node209:731299:731299 [3] NCCL INFO NET/Socket : Using [0]ens6f0np0:172.17.26.129<0>
node209:731299:731299 [3] NCCL INFO Using network Socket
node209:731296:731715 [0] NCCL INFO Channel 00/02 :    0   1   2   3
node209:731296:731715 [0] NCCL INFO Channel 01/02 :    0   1   2   3
node209:731296:731715 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
node209:731296:731715 [0] NCCL INFO Setting affinity for GPU 0 to ff,fff00000,000fffff
node209:731297:731716 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
node209:731297:731716 [1] NCCL INFO Setting affinity for GPU 1 to ff,fff00000,000fffff
node209:731298:731717 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
node209:731298:731717 [2] NCCL INFO Setting affinity for GPU 2 to ff,fff00000,000fffff
node209:731299:731718 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
node209:731299:731718 [3] NCCL INFO Setting affinity for GPU 3 to ff,fff00000,000fffff
node209:731297:731716 [1] NCCL INFO Channel 00 : 1[5e000] -> 2[5f000] via P2P/IPC
node209:731298:731717 [2] NCCL INFO Channel 00 : 2[5f000] -> 3[62000] via P2P/IPC
node209:731299:731718 [3] NCCL INFO Channel 00 : 3[62000] -> 0[5b000] via P2P/IPC
node209:731296:731715 [0] NCCL INFO Channel 00 : 0[5b000] -> 1[5e000] via P2P/IPC
node209:731298:731717 [2] NCCL INFO Channel 01 : 2[5f000] -> 3[62000] via P2P/IPC
node209:731297:731716 [1] NCCL INFO Channel 01 : 1[5e000] -> 2[5f000] via P2P/IPC
node209:731299:731718 [3] NCCL INFO Channel 01 : 3[62000] -> 0[5b000] via P2P/IPC
node209:731296:731715 [0] NCCL INFO Channel 01 : 0[5b000] -> 1[5e000] via P2P/IPC
node209:731296:731715 [0] NCCL INFO Connected all rings
node209:731299:731718 [3] NCCL INFO Connected all rings
node209:731298:731717 [2] NCCL INFO Connected all rings
node209:731299:731718 [3] NCCL INFO Channel 00 : 3[62000] -> 2[5f000] via P2P/IPC
node209:731299:731718 [3] NCCL INFO Channel 01 : 3[62000] -> 2[5f000] via P2P/IPC
node209:731298:731717 [2] NCCL INFO Channel 00 : 2[5f000] -> 1[5e000] via P2P/IPC
node209:731297:731716 [1] NCCL INFO Connected all rings
node209:731298:731717 [2] NCCL INFO Channel 01 : 2[5f000] -> 1[5e000] via P2P/IPC
node209:731299:731718 [3] NCCL INFO Connected all trees
node209:731299:731718 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node209:731299:731718 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node209:731297:731716 [1] NCCL INFO Channel 00 : 1[5e000] -> 0[5b000] via P2P/IPC
node209:731297:731716 [1] NCCL INFO Channel 01 : 1[5e000] -> 0[5b000] via P2P/IPC
node209:731298:731717 [2] NCCL INFO Connected all trees
node209:731298:731717 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node209:731298:731717 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node209:731296:731715 [0] NCCL INFO Connected all trees
node209:731297:731716 [1] NCCL INFO Connected all trees
node209:731296:731715 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node209:731296:731715 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node209:731297:731716 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node209:731297:731716 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node209:731298:731717 [2] NCCL INFO comm 0x7f92c0003010 rank 2 nranks 4 cudaDev 2 busId 5f000 - Init COMPLETE
node209:731296:731715 [0] NCCL INFO comm 0x7fc888003010 rank 0 nranks 4 cudaDev 0 busId 5b000 - Init COMPLETE
node209:731297:731716 [1] NCCL INFO comm 0x7fa954003010 rank 1 nranks 4 cudaDev 1 busId 5e000 - Init COMPLETE
node209:731296:731296 [0] NCCL INFO Launch mode Parallel
node209:731299:731718 [3] NCCL INFO comm 0x7fb3c0003010 rank 3 nranks 4 cudaDev 3 busId 62000 - Init COMPLETE
05/17 17:28:11 - mmengine - INFO - ------------------------------
05/17 17:28:11 - mmengine - INFO - The length of training dataset: 1938
05/17 17:28:11 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:28:11 - mmengine - INFO - ------------------------------
05/17 17:28:11 - mmengine - INFO - The length of training dataset: 1938
05/17 17:28:11 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:28:11 - mmengine - INFO - ------------------------------
05/17 17:28:11 - mmengine - INFO - ------------------------------
05/17 17:28:11 - mmengine - INFO - The length of training dataset: 1938
05/17 17:28:11 - mmengine - INFO - The length of training dataset: 1938
05/17 17:28:11 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
05/17 17:28:11 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:28:11 - mmengine - INFO - ------------------------------
05/17 17:28:11 - mmengine - INFO - The length of training dataset: 486
05/17 17:28:11 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:28:11 - mmengine - INFO - ------------------------------
05/17 17:28:11 - mmengine - INFO - The length of training dataset: 486
05/17 17:28:11 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:28:11 - mmengine - INFO - ------------------------------
05/17 17:28:11 - mmengine - INFO - The length of training dataset: 486
05/17 17:28:11 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:28:11 - mmengine - INFO - ------------------------------
05/17 17:28:11 - mmengine - INFO - The length of training dataset: 486
05/17 17:28:11 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:root:Project config
INFO:root:model:
  base_learning_rate: 4.5e-06
  target: src.models.autoencoder.PoseAutoencoder
  params:
    monitor: val/rec_loss
    embed_dim: 16
    euler_convention: XYZ
    activation: relu
    dropout_prob_init: 1.0
    dropout_prob_final: 0.7
    pose_conditioned_generation_steps: 7000
    dropout_warmup_steps: 5000
    add_noise_to_z_obj: true
    train_on_yaw: true
    lossconfig:
      target: src.modules.losses.PoseLoss
      params:
        encoder_pretrain_steps: 750
        disc_start: 10000
        kl_weight_obj: 1.0
        kl_weight_bbox: 1.0e-06
        disc_weight: 0.5
        pose_weight: 80000
        fill_factor_weight: 500000
        class_weight: 1000000
        bbox_weight: 200000
        pose_loss_fn: l1
        mask_weight: 0
        mask_loss_fn: l2
        disc_in_channels: 3
        num_classes: 1
        dataset_stats_path: dataset_stats/NuScenesTrain-old.pkl
        train_on_yaw: true
    pose_decoder_config:
      target: src.modules.autoencodermodules.pose_decoder.PoseDecoderSpatialVAE
      params:
        num_classes: 1
        num_channels: 16
        'n': 16
        m: 16
        hidden_dim: 500
        num_layers: 2
        activation: tanh
        resid: false
    pose_encoder_config:
      target: src.modules.autoencodermodules.pose_encoder.PoseEncoderSpatialVAE
      params:
        num_classes: 1
        num_channels: 16
        'n': 16
        m: 16
        hidden_dim: 500
        num_layers: 2
        activation: swish
    ddconfig:
      double_z: true
      z_channels: 16
      resolution: 64
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult:
      - 1
      - 1
      - 2
      - 2
      - 4
      num_res_blocks: 2
      attn_resolutions:
      - 16
      dropout: 0.0
data:
  data_root: data/nuscenes
  target: src.data.preprocessing.data_modules.DataModuleFromConfig
  params:
    batch_size: 4
    num_workers: 0
    wrap: true
    persistent_workers: false
    train:
      target: src.data.datasets.nuscenes.NuScenesTrainMini
      params:
        data_root: data/nuscenes
        pipeline: []
        box_type_3d: Camera
        load_type: frame_based
        modality:
          use_camera: true
          use_lidar: false
        filter_empty_gt: false
        test_mode: false
        with_velocity: false
        use_valid_flag: false
        label_names:
        - car
        patch_height: 256
        patch_aspect_ratio: 1.0
        perturb_center: true
        perturb_scale: true
    validation:
      target: src.data.datasets.nuscenes.NuScenesValidationMini
      params:
        data_root: data/nuscenes
        pipeline: []
        box_type_3d: Camera
        load_type: frame_based
        modality:
          use_camera: true
          use_lidar: false
        filter_empty_gt: false
        test_mode: false
        with_velocity: false
        use_valid_flag: false
        label_names:
        - car
        patch_height: 256
        patch_aspect_ratio: 1.0
        perturb_center: false

INFO:root:Lightning config
INFO:root:callbacks:
  image_logger:
    target: src.util.callbacks.ImageLogger
    params:
      batch_frequency: 1000
      max_images: 8
      increase_log_steps: true
      disable_local_logging: false
  progress_bar:
    target: src.util.callbacks.TQDMProgressBar
    params:
      refresh_rate: 1
      process_position: 0
  device_stats_monitor:
    target: src.util.callbacks.DeviceStatsMonitor
trainer:
  accumulate_grad_batches: 1
  accelerator: gpu
  max_epochs: 1000
  devices: '4'


  | Name            | Type                  | Params
----------------------------------------------------------
0 | encoder         | FeatEncoder           | 26.7 M
1 | decoder         | FeatDecoder           | 39.0 M
2 | loss            | PoseLoss              | 17.5 M
3 | quant_conv_obj  | Conv2d                | 1.1 K 
4 | quant_conv_pose | Conv2d                | 528   
5 | post_quant_conv | Conv2d                | 272   
6 | pose_decoder    | PoseDecoderSpatialVAE | 2.3 M 
7 | pose_encoder    | PoseEncoderSpatialVAE | 3.1 M 
----------------------------------------------------------
73.8 M    Trainable params
14.7 M    Non-trainable params
88.6 M    Total params
354.204   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 104 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/data/datasets/nuscenes.py:470: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  patch_size_original = torch.tensor(patch_size_original, dtype=torch.float32, requires_grad=False)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/data/datasets/nuscenes.py:470: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  patch_size_original = torch.tensor(patch_size_original, dtype=torch.float32, requires_grad=False)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/data/datasets/nuscenes.py:470: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  patch_size_original = torch.tensor(patch_size_original, dtype=torch.float32, requires_grad=False)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/data/datasets/nuscenes.py:470: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  patch_size_original = torch.tensor(patch_size_original, dtype=torch.float32, requires_grad=False)
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:84: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 4. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/rec_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/total_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/logvar', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/kl_loss_obj', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/nll_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/weighted_nll_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/d_weight', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/disc_factor', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/g_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/pose_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/weighted_pose_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/mask_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/weighted_mask_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/class_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/weighted_class_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/bbox_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/weighted_bbox_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/t1_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/t2_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/t3_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/v3_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/kl_loss_bbox', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/weighted_kl_loss_bbox', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/weighted_kl_loss_obj', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/fill_factor_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/weighted_fill_factor_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/disc_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/logits_real', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/logits_fake', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 104 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py:424: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  log["reconstructions_rgb"] = torch.tensor(xrec_rgb)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py:425: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  log["perturbed_pose_reconstruction_rgb"] = torch.tensor(xrec_perturbed_pose_rgb)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py:427: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  log["inputs_rgb"] = torch.tensor(x_rgb)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py:424: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  log["reconstructions_rgb"] = torch.tensor(xrec_rgb)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py:425: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  log["perturbed_pose_reconstruction_rgb"] = torch.tensor(xrec_perturbed_pose_rgb)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py:427: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  log["inputs_rgb"] = torch.tensor(x_rgb)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py:424: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  log["reconstructions_rgb"] = torch.tensor(xrec_rgb)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py:425: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  log["perturbed_pose_reconstruction_rgb"] = torch.tensor(xrec_perturbed_pose_rgb)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py:427: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  log["inputs_rgb"] = torch.tensor(x_rgb)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py:424: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  log["reconstructions_rgb"] = torch.tensor(xrec_rgb)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py:425: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  log["perturbed_pose_reconstruction_rgb"] = torch.tensor(xrec_perturbed_pose_rgb)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py:427: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  log["inputs_rgb"] = torch.tensor(x_rgb)
Sanity Checking: 0it [00:00, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:01<00:01,  1.86s/it]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]                                                                           Training: 0it [00:00, ?it/s]Training:   0%|          | 0/153 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/153 [00:00<?, ?it/s] Epoch 0:   1%|          | 1/153 [00:02<06:26,  2.54s/it]Epoch 0:   1%|          | 1/153 [00:02<06:26,  2.54s/it, loss=6.03e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.21e+6, discloss_step=0.000]Epoch 0:   1%|▏         | 2/153 [00:04<05:27,  2.17s/it, loss=6.03e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.21e+6, discloss_step=0.000]Epoch 0:   1%|▏         | 2/153 [00:04<05:27,  2.17s/it, loss=7.73e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.89e+6, discloss_step=0.000]Epoch 0:   2%|▏         | 3/153 [00:05<04:38,  1.86s/it, loss=7.73e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.89e+6, discloss_step=0.000]Epoch 0:   2%|▏         | 3/153 [00:05<04:38,  1.86s/it, loss=8.09e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.76e+6, discloss_step=0.000]Epoch 0:   3%|▎         | 4/153 [00:08<05:00,  2.01s/it, loss=8.09e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.76e+6, discloss_step=0.000]Epoch 0:   3%|▎         | 4/153 [00:08<05:00,  2.01s/it, loss=7.83e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.41e+6, discloss_step=0.000]Epoch 0:   3%|▎         | 5/153 [00:09<04:28,  1.81s/it, loss=7.83e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.41e+6, discloss_step=0.000]Epoch 0:   3%|▎         | 5/153 [00:09<04:28,  1.81s/it, loss=7.74e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.48e+6, discloss_step=0.000]Epoch 0:   4%|▍         | 6/153 [00:10<04:24,  1.80s/it, loss=7.74e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.48e+6, discloss_step=0.000]Epoch 0:   4%|▍         | 6/153 [00:10<04:24,  1.80s/it, loss=8.28e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.19e+6, discloss_step=0.000]Epoch 0:   5%|▍         | 7/153 [00:12<04:15,  1.75s/it, loss=8.28e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.19e+6, discloss_step=0.000]Epoch 0:   5%|▍         | 7/153 [00:12<04:15,  1.75s/it, loss=7.99e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.26e+6, discloss_step=0.000]Epoch 0:   5%|▌         | 8/153 [00:14<04:20,  1.80s/it, loss=7.99e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.26e+6, discloss_step=0.000]Epoch 0:   5%|▌         | 8/153 [00:14<04:20,  1.80s/it, loss=7.53e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=8.65e+5, discloss_step=0.000]Epoch 0:   6%|▌         | 9/153 [00:15<04:08,  1.72s/it, loss=7.53e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=8.65e+5, discloss_step=0.000]Epoch 0:   6%|▌         | 9/153 [00:15<04:08,  1.72s/it, loss=6.92e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.06e+5, discloss_step=0.000]Epoch 0:   7%|▋         | 10/153 [00:16<04:01,  1.69s/it, loss=6.92e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.06e+5, discloss_step=0.000]Epoch 0:   7%|▋         | 10/153 [00:16<04:01,  1.69s/it, loss=6.61e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=7.63e+5, discloss_step=0.000]Epoch 0:   7%|▋         | 11/153 [00:18<03:55,  1.66s/it, loss=6.61e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=7.63e+5, discloss_step=0.000]Epoch 0:   7%|▋         | 11/153 [00:18<03:55,  1.66s/it, loss=6.29e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=5.55e+5, discloss_step=0.000]Epoch 0:   8%|▊         | 12/153 [00:19<03:49,  1.63s/it, loss=6.29e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=5.55e+5, discloss_step=0.000]Epoch 0:   8%|▊         | 12/153 [00:19<03:49,  1.63s/it, loss=5.86e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.03e+6, discloss_step=0.000]Epoch 0:   8%|▊         | 13/153 [00:21<03:47,  1.62s/it, loss=5.86e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.03e+6, discloss_step=0.000]Epoch 0:   8%|▊         | 13/153 [00:21<03:47,  1.62s/it, loss=5.22e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.82e+5, discloss_step=0.000]Epoch 0:   9%|▉         | 14/153 [00:22<03:44,  1.62s/it, loss=5.22e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.82e+5, discloss_step=0.000]Epoch 0:   9%|▉         | 14/153 [00:22<03:44,  1.62s/it, loss=4.73e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.22e+5, discloss_step=0.000]Epoch 0:  10%|▉         | 15/153 [00:24<03:43,  1.62s/it, loss=4.73e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.22e+5, discloss_step=0.000]Epoch 0:  10%|▉         | 15/153 [00:24<03:43,  1.62s/it, loss=4.25e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=5.21e+5, discloss_step=0.000]Epoch 0:  10%|█         | 16/153 [00:26<03:46,  1.66s/it, loss=4.25e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=5.21e+5, discloss_step=0.000]Epoch 0:  10%|█         | 16/153 [00:26<03:46,  1.66s/it, loss=3.41e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=5.22e+5, discloss_step=0.000]Epoch 0:  11%|█         | 17/153 [00:27<03:41,  1.63s/it, loss=3.41e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=5.22e+5, discloss_step=0.000]Epoch 0:  11%|█         | 17/153 [00:27<03:41,  1.63s/it, loss=3.08e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=5.85e+5, discloss_step=0.000]Epoch 0:  12%|█▏        | 18/153 [00:29<03:38,  1.62s/it, loss=3.08e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=5.85e+5, discloss_step=0.000]Epoch 0:  12%|█▏        | 18/153 [00:29<03:38,  1.62s/it, loss=3.07e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=8.52e+5, discloss_step=0.000]Epoch 0:  12%|█▏        | 19/153 [00:30<03:36,  1.61s/it, loss=3.07e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=8.52e+5, discloss_step=0.000]Epoch 0:  12%|█▏        | 19/153 [00:30<03:36,  1.61s/it, loss=3.09e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.49e+5, discloss_step=0.000]Epoch 0:  13%|█▎        | 20/153 [00:32<03:34,  1.61s/it, loss=3.09e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.49e+5, discloss_step=0.000]Epoch 0:  13%|█▎        | 20/153 [00:32<03:34,  1.61s/it, loss=2.89e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.6e+5, discloss_step=0.000] Epoch 0:  14%|█▎        | 21/153 [00:33<03:31,  1.60s/it, loss=2.89e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.6e+5, discloss_step=0.000]Epoch 0:  14%|█▎        | 21/153 [00:33<03:31,  1.60s/it, loss=2.74e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.6e+5, discloss_step=0.000]Epoch 0:  14%|█▍        | 22/153 [00:34<03:27,  1.59s/it, loss=2.74e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.6e+5, discloss_step=0.000]Epoch 0:  14%|█▍        | 22/153 [00:34<03:27,  1.59s/it, loss=2.53e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=6.15e+5, discloss_step=0.000]Epoch 0:  15%|█▌        | 23/153 [00:36<03:27,  1.59s/it, loss=2.53e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=6.15e+5, discloss_step=0.000]Epoch 0:  15%|█▌        | 23/153 [00:36<03:27,  1.59s/it, loss=2.44e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.9e+5, discloss_step=0.000] Epoch 0:  16%|█▌        | 24/153 [00:38<03:25,  1.59s/it, loss=2.44e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.9e+5, discloss_step=0.000]Epoch 0:  16%|█▌        | 24/153 [00:38<03:25,  1.59s/it, loss=2.4e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.5e+5, discloss_step=0.000] Epoch 0:  16%|█▋        | 25/153 [00:39<03:23,  1.59s/it, loss=2.4e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.5e+5, discloss_step=0.000]Epoch 0:  16%|█▋        | 25/153 [00:39<03:23,  1.59s/it, loss=2.3e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.14e+5, discloss_step=0.000]Epoch 0:  17%|█▋        | 26/153 [00:40<03:20,  1.58s/it, loss=2.3e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.14e+5, discloss_step=0.000]Epoch 0:  17%|█▋        | 26/153 [00:40<03:20,  1.58s/it, loss=2.19e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.08e+5, discloss_step=0.000]Epoch 0:  18%|█▊        | 27/153 [00:42<03:18,  1.58s/it, loss=2.19e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.08e+5, discloss_step=0.000]Epoch 0:  18%|█▊        | 27/153 [00:42<03:18,  1.58s/it, loss=2.13e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.57e+5, discloss_step=0.000]Epoch 0:  18%|█▊        | 28/153 [00:44<03:16,  1.57s/it, loss=2.13e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.57e+5, discloss_step=0.000]Epoch 0:  18%|█▊        | 28/153 [00:44<03:16,  1.57s/it, loss=1.95e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.91e+5, discloss_step=0.000]Epoch 0:  19%|█▉        | 29/153 [00:45<03:13,  1.56s/it, loss=1.95e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.91e+5, discloss_step=0.000]Epoch 0:  19%|█▉        | 29/153 [00:45<03:13,  1.56s/it, loss=1.89e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.4e+5, discloss_step=0.000] Epoch 0:  20%|█▉        | 30/153 [00:46<03:11,  1.55s/it, loss=1.89e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.4e+5, discloss_step=0.000]Epoch 0:  20%|█▉        | 30/153 [00:46<03:11,  1.55s/it, loss=1.88e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.33e+5, discloss_step=0.000]Epoch 0:  20%|██        | 31/153 [00:48<03:10,  1.56s/it, loss=1.88e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.33e+5, discloss_step=0.000]Epoch 0:  20%|██        | 31/153 [00:48<03:10,  1.56s/it, loss=1.96e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.24e+5, discloss_step=0.000]Epoch 0:  21%|██        | 32/153 [00:50<03:12,  1.59s/it, loss=1.96e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.24e+5, discloss_step=0.000]Epoch 0:  21%|██        | 32/153 [00:50<03:12,  1.59s/it, loss=1.85e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.94e+5, discloss_step=0.000]Epoch 0:  22%|██▏       | 33/153 [00:52<03:09,  1.58s/it, loss=1.85e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.94e+5, discloss_step=0.000]Epoch 0:  22%|██▏       | 33/153 [00:52<03:09,  1.58s/it, loss=1.87e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.24e+5, discloss_step=0.000]Epoch 0:  22%|██▏       | 34/153 [00:53<03:06,  1.57s/it, loss=1.87e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.24e+5, discloss_step=0.000]Epoch 0:  22%|██▏       | 34/153 [00:53<03:06,  1.57s/it, loss=2.03e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=6.72e+5, discloss_step=0.000]Epoch 0:  23%|██▎       | 35/153 [00:55<03:05,  1.57s/it, loss=2.03e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=6.72e+5, discloss_step=0.000]Epoch 0:  23%|██▎       | 35/153 [00:55<03:05,  1.57s/it, loss=2.05e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.54e+5, discloss_step=0.000]Epoch 0:  24%|██▎       | 36/153 [00:56<03:03,  1.57s/it, loss=2.05e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.54e+5, discloss_step=0.000]Epoch 0:  24%|██▎       | 36/153 [00:56<03:03,  1.57s/it, loss=2.13e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.76e+5, discloss_step=0.000]Epoch 0:  24%|██▍       | 37/153 [00:58<03:01,  1.57s/it, loss=2.13e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.76e+5, discloss_step=0.000]Epoch 0:  24%|██▍       | 37/153 [00:58<03:01,  1.57s/it, loss=2.35e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=9.01e+5, discloss_step=0.000]Epoch 0:  25%|██▍       | 38/153 [00:59<02:59,  1.56s/it, loss=2.35e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=9.01e+5, discloss_step=0.000]Epoch 0:  25%|██▍       | 38/153 [00:59<02:59,  1.56s/it, loss=2.32e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.23e+5, discloss_step=0.000]Epoch 0:  25%|██▌       | 39/153 [01:01<02:58,  1.57s/it, loss=2.32e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.23e+5, discloss_step=0.000]Epoch 0:  25%|██▌       | 39/153 [01:01<02:58,  1.57s/it, loss=2.32e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.42e+5, discloss_step=0.000]Epoch 0:  26%|██▌       | 40/153 [01:02<02:56,  1.57s/it, loss=2.32e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.42e+5, discloss_step=0.000]Epoch 0:  26%|██▌       | 40/153 [01:02<02:56,  1.57s/it, loss=2.3e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.94e+5, discloss_step=0.000] Epoch 0:  27%|██▋       | 41/153 [01:04<02:55,  1.57s/it, loss=2.3e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.94e+5, discloss_step=0.000]Epoch 0:  27%|██▋       | 41/153 [01:04<02:55,  1.57s/it, loss=2.27e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.62e+5, discloss_step=0.000]Epoch 0:  27%|██▋       | 42/153 [01:05<02:53,  1.56s/it, loss=2.27e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.62e+5, discloss_step=0.000]Epoch 0:  27%|██▋       | 42/153 [01:05<02:53,  1.56s/it, loss=2.28e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.09e+5, discloss_step=0.000]Epoch 0:  28%|██▊       | 43/153 [01:07<02:51,  1.56s/it, loss=2.28e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.09e+5, discloss_step=0.000]Epoch 0:  28%|██▊       | 43/153 [01:07<02:51,  1.56s/it, loss=2.23e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.3e+5, discloss_step=0.000] Epoch 0:  29%|██▉       | 44/153 [01:08<02:49,  1.56s/it, loss=2.23e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.3e+5, discloss_step=0.000]Epoch 0:  29%|██▉       | 44/153 [01:08<02:49,  1.56s/it, loss=2.09e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.84e+5, discloss_step=0.000]Epoch 0:  29%|██▉       | 45/153 [01:10<02:48,  1.56s/it, loss=2.09e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.84e+5, discloss_step=0.000]Epoch 0:  29%|██▉       | 45/153 [01:10<02:48,  1.56s/it, loss=2.15e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.74e+5, discloss_step=0.000]Epoch 0:  30%|███       | 46/153 [01:11<02:46,  1.56s/it, loss=2.15e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.74e+5, discloss_step=0.000]Epoch 0:  30%|███       | 46/153 [01:11<02:46,  1.56s/it, loss=2.05e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.87e+5, discloss_step=0.000]Epoch 0:  31%|███       | 47/153 [01:13<02:44,  1.55s/it, loss=2.05e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.87e+5, discloss_step=0.000]Epoch 0:  31%|███       | 47/153 [01:13<02:44,  1.55s/it, loss=1.73e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.63e+5, discloss_step=0.000]Epoch 0:  31%|███▏      | 48/153 [01:14<02:43,  1.55s/it, loss=1.73e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.63e+5, discloss_step=0.000]Epoch 0:  31%|███▏      | 48/153 [01:14<02:43,  1.55s/it, loss=1.69e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.33e+5, discloss_step=0.000]Epoch 0:  32%|███▏      | 49/153 [01:15<02:41,  1.55s/it, loss=1.69e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.33e+5, discloss_step=0.000]Epoch 0:  32%|███▏      | 49/153 [01:15<02:41,  1.55s/it, loss=1.65e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.71e+5, discloss_step=0.000]Epoch 0:  33%|███▎      | 50/153 [01:17<02:39,  1.55s/it, loss=1.65e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.71e+5, discloss_step=0.000]Epoch 0:  33%|███▎      | 50/153 [01:17<02:39,  1.55s/it, loss=1.63e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.43e+5, discloss_step=0.000]Epoch 0:  33%|███▎      | 51/153 [01:18<02:37,  1.54s/it, loss=1.63e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.43e+5, discloss_step=0.000]Epoch 0:  33%|███▎      | 51/153 [01:18<02:37,  1.54s/it, loss=1.55e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2e+5, discloss_step=0.000]   Epoch 0:  34%|███▍      | 52/153 [01:20<02:35,  1.54s/it, loss=1.55e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2e+5, discloss_step=0.000]Epoch 0:  34%|███▍      | 52/153 [01:20<02:35,  1.54s/it, loss=1.45e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.15e+5, discloss_step=0.000]Epoch 0:  35%|███▍      | 53/153 [01:21<02:34,  1.54s/it, loss=1.45e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.15e+5, discloss_step=0.000]Epoch 0:  35%|███▍      | 53/153 [01:21<02:34,  1.54s/it, loss=1.46e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.49e+5, discloss_step=0.000]Epoch 0:  35%|███▌      | 54/153 [01:23<02:33,  1.55s/it, loss=1.46e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.49e+5, discloss_step=0.000]Epoch 0:  35%|███▌      | 54/153 [01:23<02:33,  1.55s/it, loss=1.47e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.02e+5, discloss_step=0.000]Epoch 0:  36%|███▌      | 55/153 [01:25<02:31,  1.55s/it, loss=1.47e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.02e+5, discloss_step=0.000]Epoch 0:  36%|███▌      | 55/153 [01:25<02:31,  1.55s/it, loss=1.38e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.99e+5, discloss_step=0.000]Epoch 0:  37%|███▋      | 56/153 [01:26<02:30,  1.55s/it, loss=1.38e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.99e+5, discloss_step=0.000]Epoch 0:  37%|███▋      | 56/153 [01:26<02:30,  1.55s/it, loss=1.45e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.18e+5, discloss_step=0.000]Epoch 0:  37%|███▋      | 57/153 [01:28<02:28,  1.55s/it, loss=1.45e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.18e+5, discloss_step=0.000]Epoch 0:  37%|███▋      | 57/153 [01:28<02:28,  1.55s/it, loss=1.47e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]Epoch 0:  38%|███▊      | 58/153 [01:29<02:27,  1.55s/it, loss=1.47e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]Epoch 0:  38%|███▊      | 58/153 [01:29<02:27,  1.55s/it, loss=1.51e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.04e+5, discloss_step=0.000]Epoch 0:  39%|███▊      | 59/153 [01:31<02:25,  1.55s/it, loss=1.51e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.04e+5, discloss_step=0.000]Epoch 0:  39%|███▊      | 59/153 [01:31<02:25,  1.55s/it, loss=1.54e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.42e+5, discloss_step=0.000]Epoch 0:  39%|███▉      | 60/153 [01:33<02:24,  1.55s/it, loss=1.54e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.42e+5, discloss_step=0.000]Epoch 0:  39%|███▉      | 60/153 [01:33<02:24,  1.55s/it, loss=1.6e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.58e+5, discloss_step=0.000] Epoch 0:  40%|███▉      | 61/153 [01:34<02:22,  1.55s/it, loss=1.6e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.58e+5, discloss_step=0.000]Epoch 0:  40%|███▉      | 61/153 [01:34<02:22,  1.55s/it, loss=1.65e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.94e+5, discloss_step=0.000]Epoch 0:  41%|████      | 62/153 [01:36<02:21,  1.56s/it, loss=1.65e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.94e+5, discloss_step=0.000]Epoch 0:  41%|████      | 62/153 [01:36<02:21,  1.56s/it, loss=1.7e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.09e+5, discloss_step=0.000] Epoch 0:  41%|████      | 63/153 [01:37<02:19,  1.55s/it, loss=1.7e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.09e+5, discloss_step=0.000]Epoch 0:  41%|████      | 63/153 [01:37<02:19,  1.55s/it, loss=1.74e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.35e+5, discloss_step=0.000]Epoch 0:  42%|████▏     | 64/153 [01:39<02:18,  1.56s/it, loss=1.74e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.35e+5, discloss_step=0.000]Epoch 0:  42%|████▏     | 64/153 [01:39<02:18,  1.56s/it, loss=1.72e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.66e+5, discloss_step=0.000]Epoch 0:  42%|████▏     | 65/153 [01:41<02:16,  1.56s/it, loss=1.72e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.66e+5, discloss_step=0.000]Epoch 0:  42%|████▏     | 65/153 [01:41<02:16,  1.56s/it, loss=1.7e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.62e+5, discloss_step=0.000] Epoch 0:  43%|████▎     | 66/153 [01:42<02:15,  1.56s/it, loss=1.7e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.62e+5, discloss_step=0.000]Epoch 0:  43%|████▎     | 66/153 [01:42<02:15,  1.56s/it, loss=2.17e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.36e+6, discloss_step=0.000]Epoch 0:  44%|████▍     | 67/153 [01:44<02:13,  1.55s/it, loss=2.17e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.36e+6, discloss_step=0.000]Epoch 0:  44%|████▍     | 67/153 [01:44<02:13,  1.55s/it, loss=2.13e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.44e+5, discloss_step=0.000]Epoch 0:  44%|████▍     | 68/153 [01:45<02:12,  1.55s/it, loss=2.13e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.44e+5, discloss_step=0.000]Epoch 0:  44%|████▍     | 68/153 [01:45<02:12,  1.55s/it, loss=2.06e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.52e+5, discloss_step=0.000]Epoch 0:  45%|████▌     | 69/153 [01:47<02:10,  1.55s/it, loss=2.06e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.52e+5, discloss_step=0.000]Epoch 0:  45%|████▌     | 69/153 [01:47<02:10,  1.55s/it, loss=2e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.2e+5, discloss_step=0.000]    Epoch 0:  46%|████▌     | 70/153 [01:48<02:08,  1.55s/it, loss=2e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.2e+5, discloss_step=0.000]Epoch 0:  46%|████▌     | 70/153 [01:48<02:08,  1.55s/it, loss=1.93e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.2e+5, discloss_step=0.000]Epoch 0:  46%|████▋     | 71/153 [01:49<02:06,  1.55s/it, loss=1.93e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.2e+5, discloss_step=0.000]Epoch 0:  46%|████▋     | 71/153 [01:49<02:06,  1.55s/it, loss=1.93e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3e+5, discloss_step=0.000]  Epoch 0:  47%|████▋     | 72/153 [01:51<02:05,  1.54s/it, loss=1.93e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3e+5, discloss_step=0.000]Epoch 0:  47%|████▋     | 72/153 [01:51<02:05,  1.54s/it, loss=1.93e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.01e+5, discloss_step=0.000]Epoch 0:  48%|████▊     | 73/153 [01:52<02:03,  1.54s/it, loss=1.93e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.01e+5, discloss_step=0.000]Epoch 0:  48%|████▊     | 73/153 [01:52<02:03,  1.54s/it, loss=1.9e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.75e+5, discloss_step=0.000] Epoch 0:  48%|████▊     | 74/153 [01:53<02:01,  1.54s/it, loss=1.9e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.75e+5, discloss_step=0.000]Epoch 0:  48%|████▊     | 74/153 [01:53<02:01,  1.54s/it, loss=1.89e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.57e+5, discloss_step=0.000]Epoch 0:  49%|████▉     | 75/153 [01:55<02:00,  1.54s/it, loss=1.89e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.57e+5, discloss_step=0.000]Epoch 0:  49%|████▉     | 75/153 [01:55<02:00,  1.54s/it, loss=1.89e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.48e+5, discloss_step=0.000]Epoch 0:  50%|████▉     | 76/153 [01:57<01:58,  1.54s/it, loss=1.89e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.48e+5, discloss_step=0.000]Epoch 0:  50%|████▉     | 76/153 [01:57<01:58,  1.54s/it, loss=1.34e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.54e+5, discloss_step=0.000]Epoch 0:  50%|█████     | 77/153 [01:58<01:57,  1.54s/it, loss=1.34e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.54e+5, discloss_step=0.000]Epoch 0:  50%|█████     | 77/153 [01:58<01:57,  1.54s/it, loss=1.35e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.8e+5, discloss_step=0.000] Epoch 0:  51%|█████     | 78/153 [01:59<01:55,  1.54s/it, loss=1.35e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.8e+5, discloss_step=0.000]Epoch 0:  51%|█████     | 78/153 [01:59<01:55,  1.54s/it, loss=1.33e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.12e+5, discloss_step=0.000]Epoch 0:  52%|█████▏    | 79/153 [02:01<01:53,  1.54s/it, loss=1.33e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.12e+5, discloss_step=0.000]Epoch 0:  52%|█████▏    | 79/153 [02:01<01:53,  1.54s/it, loss=1.36e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.68e+5, discloss_step=0.000]Epoch 0:  52%|█████▏    | 80/153 [02:02<01:52,  1.54s/it, loss=1.36e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.68e+5, discloss_step=0.000]Epoch 0:  52%|█████▏    | 80/153 [02:02<01:52,  1.54s/it, loss=1.33e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.65e+5, discloss_step=0.000]Epoch 0:  53%|█████▎    | 81/153 [02:04<01:50,  1.53s/it, loss=1.33e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.65e+5, discloss_step=0.000]Epoch 0:  53%|█████▎    | 81/153 [02:04<01:50,  1.54s/it, loss=1.26e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.68e+5, discloss_step=0.000]Epoch 0:  54%|█████▎    | 82/153 [02:05<01:48,  1.53s/it, loss=1.26e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.68e+5, discloss_step=0.000]Epoch 0:  54%|█████▎    | 82/153 [02:05<01:48,  1.53s/it, loss=1.39e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=5.59e+5, discloss_step=0.000]Epoch 0:  54%|█████▍    | 83/153 [02:07<01:47,  1.53s/it, loss=1.39e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=5.59e+5, discloss_step=0.000]Epoch 0:  54%|█████▍    | 83/153 [02:07<01:47,  1.53s/it, loss=1.37e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.18e+5, discloss_step=0.000]Epoch 0:  55%|█████▍    | 84/153 [02:08<01:45,  1.53s/it, loss=1.37e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.18e+5, discloss_step=0.000]Epoch 0:  55%|█████▍    | 84/153 [02:08<01:45,  1.53s/it, loss=1.29e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.06e+5, discloss_step=0.000]Epoch 0:  56%|█████▌    | 85/153 [02:10<01:44,  1.53s/it, loss=1.29e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.06e+5, discloss_step=0.000]Epoch 0:  56%|█████▌    | 85/153 [02:10<01:44,  1.53s/it, loss=1.28e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.38e+5, discloss_step=0.000]Epoch 0:  56%|█████▌    | 86/153 [02:11<01:42,  1.53s/it, loss=1.28e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.38e+5, discloss_step=0.000]Epoch 0:  56%|█████▌    | 86/153 [02:11<01:42,  1.53s/it, loss=1.27e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.34e+5, discloss_step=0.000]Epoch 0:  57%|█████▋    | 87/153 [02:12<01:40,  1.53s/it, loss=1.27e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.34e+5, discloss_step=0.000]Epoch 0:  57%|█████▋    | 87/153 [02:12<01:40,  1.53s/it, loss=1.23e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2e+5, discloss_step=0.000]   Epoch 0:  58%|█████▊    | 88/153 [02:14<01:39,  1.52s/it, loss=1.23e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2e+5, discloss_step=0.000]Epoch 0:  58%|█████▊    | 88/153 [02:14<01:39,  1.52s/it, loss=1.39e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=5.23e+5, discloss_step=0.000]Epoch 0:  58%|█████▊    | 89/153 [02:15<01:37,  1.52s/it, loss=1.39e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=5.23e+5, discloss_step=0.000]Epoch 0:  58%|█████▊    | 89/153 [02:15<01:37,  1.52s/it, loss=1.38e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.43e+5, discloss_step=0.000]Epoch 0:  59%|█████▉    | 90/153 [02:17<01:36,  1.52s/it, loss=1.38e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.43e+5, discloss_step=0.000]Epoch 0:  59%|█████▉    | 90/153 [02:17<01:36,  1.52s/it, loss=1.43e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.73e+5, discloss_step=0.000]Epoch 0:  59%|█████▉    | 91/153 [02:18<01:34,  1.52s/it, loss=1.43e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.73e+5, discloss_step=0.000]Epoch 0:  59%|█████▉    | 91/153 [02:18<01:34,  1.52s/it, loss=1.45e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.01e+5, discloss_step=0.000]Epoch 0:  60%|██████    | 92/153 [02:20<01:33,  1.53s/it, loss=1.45e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.01e+5, discloss_step=0.000]Epoch 0:  60%|██████    | 92/153 [02:20<01:33,  1.53s/it, loss=1.28e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.33e+5, discloss_step=0.000]Epoch 0:  61%|██████    | 93/153 [02:22<01:31,  1.53s/it, loss=1.28e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.33e+5, discloss_step=0.000]Epoch 0:  61%|██████    | 93/153 [02:22<01:31,  1.53s/it, loss=1.33e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.1e+5, discloss_step=0.000] Epoch 0:  61%|██████▏   | 94/153 [02:23<01:30,  1.53s/it, loss=1.33e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.1e+5, discloss_step=0.000]Epoch 0:  61%|██████▏   | 94/153 [02:23<01:30,  1.53s/it, loss=1.35e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.43e+5, discloss_step=0.000]Epoch 0:  62%|██████▏   | 95/153 [02:25<01:28,  1.53s/it, loss=1.35e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.43e+5, discloss_step=0.000]Epoch 0:  62%|██████▏   | 95/153 [02:25<01:28,  1.53s/it, loss=1.35e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.4e+5, discloss_step=0.000] Epoch 0:  63%|██████▎   | 96/153 [02:26<01:27,  1.53s/it, loss=1.35e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.4e+5, discloss_step=0.000]Epoch 0:  63%|██████▎   | 96/153 [02:26<01:27,  1.53s/it, loss=1.37e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.82e+5, discloss_step=0.000]Epoch 0:  63%|██████▎   | 97/153 [02:28<01:25,  1.53s/it, loss=1.37e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.82e+5, discloss_step=0.000]Epoch 0:  63%|██████▎   | 97/153 [02:28<01:25,  1.53s/it, loss=1.41e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.63e+5, discloss_step=0.000]Epoch 0:  64%|██████▍   | 98/153 [02:29<01:24,  1.53s/it, loss=1.41e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.63e+5, discloss_step=0.000]Epoch 0:  64%|██████▍   | 98/153 [02:29<01:24,  1.53s/it, loss=1.26e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.25e+5, discloss_step=0.000]Epoch 0:  65%|██████▍   | 99/153 [02:31<01:22,  1.53s/it, loss=1.26e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.25e+5, discloss_step=0.000]Epoch 0:  65%|██████▍   | 99/153 [02:31<01:22,  1.53s/it, loss=1.25e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.36e+5, discloss_step=0.000]Epoch 0:  65%|██████▌   | 100/153 [02:33<01:21,  1.53s/it, loss=1.25e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.36e+5, discloss_step=0.000]Epoch 0:  65%|██████▌   | 100/153 [02:33<01:21,  1.53s/it, loss=1.24e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.43e+5, discloss_step=0.000]Epoch 0:  66%|██████▌   | 101/153 [02:34<01:19,  1.53s/it, loss=1.24e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.43e+5, discloss_step=0.000]Epoch 0:  66%|██████▌   | 101/153 [02:34<01:19,  1.53s/it, loss=1.3e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000] Epoch 0:  67%|██████▋   | 102/153 [02:35<01:17,  1.53s/it, loss=1.3e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]Epoch 0:  67%|██████▋   | 102/153 [02:35<01:17,  1.53s/it, loss=1.3e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.4e+5, discloss_step=0.000] Epoch 0:  67%|██████▋   | 103/153 [02:37<01:16,  1.53s/it, loss=1.3e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.4e+5, discloss_step=0.000]Epoch 0:  67%|██████▋   | 103/153 [02:37<01:16,  1.53s/it, loss=1.26e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.38e+5, discloss_step=0.000]Epoch 0:  68%|██████▊   | 104/153 [02:38<01:14,  1.53s/it, loss=1.26e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.38e+5, discloss_step=0.000]Epoch 0:  68%|██████▊   | 104/153 [02:38<01:14,  1.53s/it, loss=1.22e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.64e+5, discloss_step=0.000]Epoch 0:  69%|██████▊   | 105/153 [02:40<01:13,  1.53s/it, loss=1.22e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.64e+5, discloss_step=0.000]Epoch 0:  69%|██████▊   | 105/153 [02:40<01:13,  1.53s/it, loss=1.23e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.53e+5, discloss_step=0.000]Epoch 0:  69%|██████▉   | 106/153 [02:41<01:11,  1.52s/it, loss=1.23e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.53e+5, discloss_step=0.000]Epoch 0:  69%|██████▉   | 106/153 [02:41<01:11,  1.52s/it, loss=1.26e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.38e+5, discloss_step=0.000]Epoch 0:  70%|██████▉   | 107/153 [02:42<01:09,  1.52s/it, loss=1.26e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.38e+5, discloss_step=0.000]Epoch 0:  70%|██████▉   | 107/153 [02:42<01:09,  1.52s/it, loss=1.24e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.26e+5, discloss_step=0.000]Epoch 0:  71%|███████   | 108/153 [02:44<01:08,  1.52s/it, loss=1.24e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.26e+5, discloss_step=0.000]Epoch 0:  71%|███████   | 108/153 [02:44<01:08,  1.52s/it, loss=1.22e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.86e+5, discloss_step=0.000]Epoch 0:  71%|███████   | 109/153 [02:45<01:06,  1.52s/it, loss=1.22e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.86e+5, discloss_step=0.000]Epoch 0:  71%|███████   | 109/153 [02:45<01:06,  1.52s/it, loss=1.2e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.02e+5, discloss_step=0.000] Epoch 0:  72%|███████▏  | 110/153 [02:47<01:05,  1.52s/it, loss=1.2e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.02e+5, discloss_step=0.000]Epoch 0:  72%|███████▏  | 110/153 [02:47<01:05,  1.52s/it, loss=1.3e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.46e+5, discloss_step=0.000]Epoch 0:  73%|███████▎  | 111/153 [02:48<01:03,  1.52s/it, loss=1.3e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=4.46e+5, discloss_step=0.000]Epoch 0:  73%|███████▎  | 111/153 [02:48<01:03,  1.52s/it, loss=1.26e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.19e+5, discloss_step=0.000]Epoch 0:  73%|███████▎  | 112/153 [02:50<01:02,  1.52s/it, loss=1.26e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.19e+5, discloss_step=0.000]Epoch 0:  73%|███████▎  | 112/153 [02:50<01:02,  1.52s/it, loss=1.5e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=7.36e+5, discloss_step=0.000] Epoch 0:  74%|███████▍  | 113/153 [02:51<01:00,  1.52s/it, loss=1.5e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=7.36e+5, discloss_step=0.000]Epoch 0:  74%|███████▍  | 113/153 [02:51<01:00,  1.52s/it, loss=1.52e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.66e+5, discloss_step=0.000]Epoch 0:  75%|███████▍  | 114/153 [02:53<00:59,  1.52s/it, loss=1.52e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.66e+5, discloss_step=0.000]Epoch 0:  75%|███████▍  | 114/153 [02:53<00:59,  1.52s/it, loss=1.51e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.44e+5, discloss_step=0.000]Epoch 0:  75%|███████▌  | 115/153 [02:54<00:57,  1.52s/it, loss=1.51e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.44e+5, discloss_step=0.000]Epoch 0:  75%|███████▌  | 115/153 [02:54<00:57,  1.52s/it, loss=1.47e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.79e+5, discloss_step=0.000]Epoch 0:  76%|███████▌  | 116/153 [02:56<00:56,  1.52s/it, loss=1.47e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.79e+5, discloss_step=0.000]Epoch 0:  76%|███████▌  | 116/153 [02:56<00:56,  1.52s/it, loss=1.42e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.38e+5, discloss_step=0.000]Epoch 0:  76%|███████▋  | 117/153 [02:57<00:54,  1.52s/it, loss=1.42e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.38e+5, discloss_step=0.000]Epoch 0:  76%|███████▋  | 117/153 [02:57<00:54,  1.52s/it, loss=1.47e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]Epoch 0:  77%|███████▋  | 118/153 [02:59<00:53,  1.52s/it, loss=1.47e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]Epoch 0:  77%|███████▋  | 118/153 [02:59<00:53,  1.52s/it, loss=1.48e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.14e+5, discloss_step=0.000]Epoch 0:  78%|███████▊  | 119/153 [03:01<00:51,  1.52s/it, loss=1.48e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.14e+5, discloss_step=0.000]Epoch 0:  78%|███████▊  | 119/153 [03:01<00:51,  1.52s/it, loss=1.5e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.4e+5, discloss_step=0.000]  Epoch 0:  78%|███████▊  | 120/153 [03:02<00:50,  1.52s/it, loss=1.5e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.4e+5, discloss_step=0.000]Epoch 0:  78%|███████▊  | 120/153 [03:02<00:50,  1.52s/it, loss=1.4e+05,/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:84: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
 v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.56e+5, discloss_step=0.000]Epoch 0:  79%|███████▉  | 121/153 [03:03<00:48,  1.52s/it, loss=1.4e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.56e+5, discloss_step=0.000]Epoch 0:  79%|███████▉  | 121/153 [03:03<00:48,  1.52s/it, loss=1.41e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.4e+5, discloss_step=0.000]Epoch 0:  80%|███████▉  | 122/153 [03:03<00:46,  1.51s/it, loss=1.41e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.4e+5, discloss_step=0.000]Epoch 0:  80%|███████▉  | 122/153 [03:03<00:46,  1.51s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/31 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/31 [00:00<?, ?it/s][A
Validation DataLoader 0:   3%|▎         | 1/31 [00:00<00:03,  9.35it/s][AEpoch 0:  80%|████████  | 123/153 [03:04<00:45,  1.50s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:   6%|▋         | 2/31 [00:01<00:17,  1.62it/s][AEpoch 0:  81%|████████  | 124/153 [03:05<00:43,  1.50s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  10%|▉         | 3/31 [00:02<00:21,  1.28it/s][AEpoch 0:  82%|████████▏ | 125/153 [03:06<00:41,  1.50s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  13%|█▎        | 4/31 [00:03<00:22,  1.17it/s][AEpoch 0:  82%|████████▏ | 126/153 [03:07<00:40,  1.49s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  16%|█▌        | 5/31 [00:04<00:22,  1.18it/s][AEpoch 0:  83%|████████▎ | 127/153 [03:08<00:38,  1.49s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  19%|█▉        | 6/31 [00:05<00:21,  1.18it/s][AEpoch 0:  84%|████████▎ | 128/153 [03:09<00:37,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  23%|██▎       | 7/31 [00:06<00:21,  1.11it/s][AEpoch 0:  84%|████████▍ | 129/153 [03:10<00:35,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  26%|██▌       | 8/31 [00:07<00:22,  1.04it/s][AEpoch 0:  85%|████████▍ | 130/153 [03:12<00:34,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  29%|██▉       | 9/31 [00:09<00:22,  1.01s/it][AEpoch 0:  86%|████████▌ | 131/153 [03:13<00:32,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  32%|███▏      | 10/31 [00:10<00:21,  1.02s/it][AEpoch 0:  86%|████████▋ | 132/153 [03:14<00:30,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  35%|███▌      | 11/31 [00:11<00:21,  1.05s/it][AEpoch 0:  87%|████████▋ | 133/153 [03:16<00:29,  1.47s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  39%|███▊      | 12/31 [00:13<00:21,  1.12s/it][AEpoch 0:  88%|████████▊ | 134/153 [03:17<00:28,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  42%|████▏     | 13/31 [00:14<00:20,  1.15s/it][AEpoch 0:  88%|████████▊ | 135/153 [03:19<00:26,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  45%|████▌     | 14/31 [00:16<00:19,  1.16s/it][AEpoch 0:  89%|████████▉ | 136/153 [03:20<00:25,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  48%|████▊     | 15/31 [00:17<00:18,  1.18s/it][AEpoch 0:  90%|████████▉ | 137/153 [03:22<00:23,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  52%|█████▏    | 16/31 [00:19<00:18,  1.22s/it][AEpoch 0:  90%|█████████ | 138/153 [03:24<00:22,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  55%|█████▍    | 17/31 [00:21<00:17,  1.25s/it][AEpoch 0:  91%|█████████ | 139/153 [03:25<00:20,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  58%|█████▊    | 18/31 [00:23<00:16,  1.29s/it][AEpoch 0:  92%|█████████▏| 140/153 [03:27<00:19,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  61%|██████▏   | 19/31 [00:24<00:15,  1.30s/it][AEpoch 0:  92%|█████████▏| 141/153 [03:29<00:17,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  65%|██████▍   | 20/31 [00:26<00:14,  1.30s/it][AEpoch 0:  93%|█████████▎| 142/153 [03:30<00:16,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  68%|██████▊   | 21/31 [00:27<00:13,  1.31s/it][AEpoch 0:  93%|█████████▎| 143/153 [03:32<00:14,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  71%|███████   | 22/31 [00:28<00:11,  1.32s/it][AEpoch 0:  94%|█████████▍| 144/153 [03:33<00:13,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  74%|███████▍  | 23/31 [00:30<00:10,  1.31s/it][AEpoch 0:  95%|█████████▍| 145/153 [03:34<00:11,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  77%|███████▋  | 24/31 [00:31<00:09,  1.33s/it][AEpoch 0:  95%|█████████▌| 146/153 [03:36<00:10,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  81%|████████  | 25/31 [00:33<00:07,  1.33s/it][AEpoch 0:  96%|█████████▌| 147/153 [03:37<00:08,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  84%|████████▍ | 26/31 [00:35<00:06,  1.35s/it][AEpoch 0:  97%|█████████▋| 148/153 [03:39<00:07,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  87%|████████▋ | 27/31 [00:36<00:05,  1.37s/it][AEpoch 0:  97%|█████████▋| 149/153 [03:41<00:05,  1.49s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  90%|█████████ | 28/31 [00:38<00:04,  1.37s/it][AEpoch 0:  98%|█████████▊| 150/153 [03:43<00:04,  1.49s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0:  94%|█████████▎| 29/31 [00:39<00:02,  1.36s/it][AEpoch 0:  99%|█████████▊| 151/153 [03:44<00:02,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:84: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Validation DataLoader 0:  97%|█████████▋| 30/31 [00:40<00:01,  1.36s/it][AEpoch 0:  99%|█████████▉| 152/153 [03:45<00:01,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
Validation DataLoader 0: 100%|██████████| 31/31 [00:41<00:00,  1.34s/it][AEpoch 0: 100%|██████████| 153/153 [03:46<00:00,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]Epoch 0: 100%|██████████| 153/153 [03:46<00:00,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000]
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('dropout_prob', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('aeloss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('discloss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
Epoch 0, global step 244: 'val/rec_loss' reached 1.08053 (best 1.08053), saving model to 'logs/2024-05-17T17-27-52_od_vae_test_1gpu/checkpoints/epoch=000000.ckpt' as top 3
                                                                        [AEpoch 0: 100%|██████████| 153/153 [03:46<00:00,  1.48s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 0:   0%|          | 0/153 [00:00<?, ?it/s, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]          Epoch 1:   0%|          | 0/153 [00:00<?, ?it/s, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   1%|          | 1/153 [00:00<01:39,  1.52it/s, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.17e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   1%|          | 1/153 [00:00<01:40,  1.52it/s, loss=1.16e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.8e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000] Epoch 1:   1%|▏         | 2/153 [00:02<02:38,  1.05s/it, loss=1.16e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.8e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   1%|▏         | 2/153 [00:02<02:38,  1.05s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.38e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   2%|▏         | 3/153 [00:03<02:59,  1.20s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.38e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   2%|▏         | 3/153 [00:03<02:59,  1.20s/it, loss=1.24e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.41e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   3%|▎         | 4/153 [00:05<03:13,  1.30s/it, loss=1.24e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.41e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   3%|▎         | 4/153 [00:05<03:13,  1.30s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.7e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000] Epoch 1:   3%|▎         | 5/153 [00:06<03:08,  1.27s/it, loss=1.21e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.7e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   3%|▎         | 5/153 [00:06<03:08,  1.27s/it, loss=1.13e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.71e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   4%|▍         | 6/153 [00:08<03:26,  1.40s/it, loss=1.13e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.71e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   4%|▍         | 6/153 [00:08<03:26,  1.40s/it, loss=1.12e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.83e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   5%|▍         | 7/153 [00:09<03:18,  1.36s/it, loss=1.12e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.83e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   5%|▍         | 7/153 [00:09<03:18,  1.36s/it, loss=1.1e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.11e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000] Epoch 1:   5%|▌         | 8/153 [00:10<03:14,  1.34s/it, loss=1.1e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.11e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   5%|▌         | 8/153 [00:10<03:14,  1.34s/it, loss=1.11e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.74e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   6%|▌         | 9/153 [00:12<03:13,  1.34s/it, loss=1.11e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.74e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   6%|▌         | 9/153 [00:12<03:13,  1.34s/it, loss=1.12e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.55e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   7%|▋         | 10/153 [00:13<03:13,  1.35s/it, loss=1.12e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.55e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   7%|▋         | 10/153 [00:13<03:13,  1.35s/it, loss=1.04e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.61e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   7%|▋         | 11/153 [00:15<03:14,  1.37s/it, loss=1.04e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.61e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   7%|▋         | 11/153 [00:15<03:14,  1.37s/it, loss=1.07e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.26e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   8%|▊         | 12/153 [00:16<03:13,  1.37s/it, loss=1.07e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.26e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   8%|▊         | 12/153 [00:16<03:13,  1.37s/it, loss=1.05e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.03e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   8%|▊         | 13/153 [00:18<03:16,  1.40s/it, loss=1.05e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.03e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   8%|▊         | 13/153 [00:18<03:16,  1.40s/it, loss=1.03e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.01e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   9%|▉         | 14/153 [00:19<03:15,  1.41s/it, loss=1.03e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.01e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:   9%|▉         | 14/153 [00:19<03:15,  1.41s/it, loss=1.04e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.95e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  10%|▉         | 15/153 [00:21<03:15,  1.42s/it, loss=1.04e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.95e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  10%|▉         | 15/153 [00:21<03:15,  1.42s/it, loss=1.08e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.43e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  10%|█         | 16/153 [00:22<03:14,  1.42s/it, loss=1.08e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.43e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  10%|█         | 16/153 [00:22<03:14,  1.42s/it, loss=1.07e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.75e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  11%|█         | 17/153 [00:24<03:12,  1.42s/it, loss=1.07e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.75e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  11%|█         | 17/153 [00:24<03:12,  1.42s/it, loss=1.12e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.08e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  12%|█▏        | 18/153 [00:25<03:10,  1.41s/it, loss=1.12e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.08e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  12%|█▏        | 18/153 [00:25<03:10,  1.41s/it, loss=1.07e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.67e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  12%|█▏        | 19/153 [00:26<03:08,  1.40s/it, loss=1.07e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.67e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  12%|█▏        | 19/153 [00:26<03:08,  1.40s/it, loss=1.03e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.9e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000] Epoch 1:  13%|█▎        | 20/153 [00:27<03:05,  1.40s/it, loss=1.03e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.9e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  13%|█▎        | 20/153 [00:27<03:05,  1.40s/it, loss=1.06e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.13e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  14%|█▎        | 21/153 [00:29<03:04,  1.40s/it, loss=1.06e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.13e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  14%|█▎        | 21/153 [00:29<03:04,  1.40s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.45e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  14%|█▍        | 22/153 [00:30<03:02,  1.40s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.45e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  14%|█▍        | 22/153 [00:30<03:02,  1.40s/it, loss=1.06e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.9e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000] Epoch 1:  15%|█▌        | 23/153 [00:31<03:00,  1.39s/it, loss=1.06e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.9e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  15%|█▌        | 23/153 [00:31<03:00,  1.39s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.18e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  16%|█▌        | 24/153 [00:33<03:00,  1.40s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.18e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  16%|█▌        | 24/153 [00:33<03:00,  1.40s/it, loss=1.06e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.7e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000] Epoch 1:  16%|█▋        | 25/153 [00:35<03:01,  1.42s/it, loss=1.06e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.7e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  16%|█▋        | 25/153 [00:35<03:01,  1.42s/it, loss=1.03e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.86e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  17%|█▋        | 26/153 [00:36<03:00,  1.42s/it, loss=1.03e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.86e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  17%|█▋        | 26/153 [00:36<03:00,  1.42s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.57e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  18%|█▊        | 27/153 [00:38<02:58,  1.42s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.57e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  18%|█▊        | 27/153 [00:38<02:58,  1.42s/it, loss=9.97e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.58e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  18%|█▊        | 28/153 [00:39<02:58,  1.43s/it, loss=9.97e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.58e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  18%|█▊        | 28/153 [00:39<02:58,  1.43s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.14e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  19%|█▉        | 29/153 [00:41<02:55,  1.42s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.14e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  19%|█▉        | 29/153 [00:41<02:55,  1.42s/it, loss=1.03e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.12e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  20%|█▉        | 30/153 [00:42<02:53,  1.41s/it, loss=1.03e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.12e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  20%|█▉        | 30/153 [00:42<02:53,  1.41s/it, loss=1.09e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.2e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000] Epoch 1:  20%|██        | 31/153 [00:43<02:51,  1.41s/it, loss=1.09e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.2e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  20%|██        | 31/153 [00:43<02:51,  1.41s/it, loss=1.1e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.65e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  21%|██        | 32/153 [00:44<02:49,  1.40s/it, loss=1.1e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.65e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  21%|██        | 32/153 [00:44<02:49,  1.40s/it, loss=1.03e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.51e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  22%|██▏       | 33/153 [00:46<02:47,  1.40s/it, loss=1.03e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.51e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  22%|██▏       | 33/153 [00:46<02:47,  1.40s/it, loss=1.07e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.11e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  22%|██▏       | 34/153 [00:47<02:45,  1.39s/it, loss=1.07e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.11e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  22%|██▏       | 34/153 [00:47<02:45,  1.39s/it, loss=1.04e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.14e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  23%|██▎       | 35/153 [00:48<02:44,  1.39s/it, loss=1.04e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.14e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  23%|██▎       | 35/153 [00:48<02:44,  1.39s/it, loss=1.06e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.12e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  24%|██▎       | 36/153 [00:50<02:43,  1.39s/it, loss=1.06e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.12e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  24%|██▎       | 36/153 [00:50<02:43,  1.39s/it, loss=1.12e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.75e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  24%|██▍       | 37/153 [00:51<02:42,  1.40s/it, loss=1.12e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.75e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  24%|██▍       | 37/153 [00:51<02:42,  1.40s/it, loss=1.09e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.99e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  25%|██▍       | 38/153 [00:53<02:41,  1.40s/it, loss=1.09e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.99e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  25%|██▍       | 38/153 [00:53<02:41,  1.40s/it, loss=1.08e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.99e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  25%|██▌       | 39/153 [00:54<02:39,  1.40s/it, loss=1.08e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.99e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  25%|██▌       | 39/153 [00:54<02:39,  1.40s/it, loss=1.05e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.56e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  26%|██▌       | 40/153 [00:56<02:38,  1.40s/it, loss=1.05e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.56e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  26%|██▌       | 40/153 [00:56<02:38,  1.40s/it, loss=9.99e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.15e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  27%|██▋       | 41/153 [00:57<02:37,  1.40s/it, loss=9.99e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.15e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  27%|██▋       | 41/153 [00:57<02:37,  1.40s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.09e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  27%|██▋       | 42/153 [00:58<02:34,  1.40s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.09e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  27%|██▋       | 42/153 [00:58<02:34,  1.40s/it, loss=1.04e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.87e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  28%|██▊       | 43/153 [01:00<02:33,  1.40s/it, loss=1.04e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.87e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  28%|██▊       | 43/153 [01:00<02:33,  1.40s/it, loss=1.06e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.52e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  29%|██▉       | 44/153 [01:01<02:31,  1.39s/it, loss=1.06e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.52e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  29%|██▉       | 44/153 [01:01<02:31,  1.39s/it, loss=1.03e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.6e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000] Epoch 1:  29%|██▉       | 45/153 [01:02<02:30,  1.39s/it, loss=1.03e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.6e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  29%|██▉       | 45/153 [01:02<02:30,  1.39s/it, loss=1e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.5e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]   Epoch 1:  30%|███       | 46/153 [01:04<02:29,  1.40s/it, loss=1e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.5e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  30%|███       | 46/153 [01:04<02:29,  1.40s/it, loss=9.25e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.24e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  31%|███       | 47/153 [01:05<02:27,  1.39s/it, loss=9.25e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.24e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  31%|███       | 47/153 [01:05<02:27,  1.39s/it, loss=9.11e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.71e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  31%|███▏      | 48/153 [01:07<02:27,  1.40s/it, loss=9.11e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.71e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  31%|███▏      | 48/153 [01:07<02:27,  1.40s/it, loss=9.14e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.06e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  32%|███▏      | 49/153 [01:08<02:25,  1.40s/it, loss=9.14e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.06e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  32%|███▏      | 49/153 [01:08<02:25,  1.40s/it, loss=9.42e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.11e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  33%|███▎      | 50/153 [01:10<02:24,  1.40s/it, loss=9.42e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.11e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  33%|███▎      | 50/153 [01:10<02:24,  1.40s/it, loss=9.03e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.38e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  33%|███▎      | 51/153 [01:11<02:23,  1.40s/it, loss=9.03e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.38e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  33%|███▎      | 51/153 [01:11<02:23,  1.40s/it, loss=9.44e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.91e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  34%|███▍      | 52/153 [01:13<02:22,  1.41s/it, loss=9.44e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.91e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  34%|███▍      | 52/153 [01:13<02:22,  1.41s/it, loss=9.27e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.52e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  35%|███▍      | 53/153 [01:14<02:20,  1.40s/it, loss=9.27e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.52e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  35%|███▍      | 53/153 [01:14<02:20,  1.40s/it, loss=9.08e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.15e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  35%|███▌      | 54/153 [01:15<02:18,  1.40s/it, loss=9.08e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.15e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  35%|███▌      | 54/153 [01:15<02:18,  1.40s/it, loss=9.57e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.58e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  36%|███▌      | 55/153 [01:17<02:17,  1.40s/it, loss=9.57e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.58e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  36%|███▌      | 55/153 [01:17<02:17,  1.40s/it, loss=1.26e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=7.58e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  37%|███▋      | 56/153 [01:18<02:15,  1.40s/it, loss=1.26e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=7.58e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  37%|███▋      | 56/153 [01:18<02:15,  1.40s/it, loss=1.31e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.15e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  37%|███▋      | 57/153 [01:20<02:14,  1.40s/it, loss=1.31e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.15e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  37%|███▋      | 57/153 [01:20<02:14,  1.40s/it, loss=1.29e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.32e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  38%|███▊      | 58/153 [01:21<02:13,  1.41s/it, loss=1.29e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.32e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  38%|███▊      | 58/153 [01:21<02:13,  1.41s/it, loss=1.32e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.78e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  39%|███▊      | 59/153 [01:23<02:12,  1.41s/it, loss=1.32e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.78e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  39%|███▊      | 59/153 [01:23<02:12,  1.41s/it, loss=1.32e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.13e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  39%|███▉      | 60/153 [01:24<02:11,  1.41s/it, loss=1.32e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.13e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  39%|███▉      | 60/153 [01:24<02:11,  1.41s/it, loss=1.36e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.05e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  40%|███▉      | 61/153 [01:26<02:10,  1.42s/it, loss=1.36e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.05e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  40%|███▉      | 61/153 [01:26<02:10,  1.42s/it, loss=1.3e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.65e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000] Epoch 1:  41%|████      | 62/153 [01:27<02:08,  1.41s/it, loss=1.3e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.65e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  41%|████      | 62/153 [01:27<02:08,  1.41s/it, loss=1.33e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.29e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  41%|████      | 63/153 [01:28<02:07,  1.41s/it, loss=1.33e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.29e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  41%|████      | 63/153 [01:28<02:07,  1.41s/it, loss=1.35e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.39e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  42%|████▏     | 64/153 [01:30<02:05,  1.41s/it, loss=1.35e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.39e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  42%|████▏     | 64/153 [01:30<02:05,  1.41s/it, loss=1.32e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.02e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  42%|████▏     | 65/153 [01:31<02:04,  1.41s/it, loss=1.32e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.02e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  42%|████▏     | 65/153 [01:31<02:04,  1.41s/it, loss=1.47e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.07e+6, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  43%|████▎     | 66/153 [01:33<02:03,  1.42s/it, loss=1.47e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.07e+6, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  43%|████▎     | 66/153 [01:33<02:03,  1.42s/it, loss=1.46e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.86e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  44%|████▍     | 67/153 [01:34<02:01,  1.42s/it, loss=1.46e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.86e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  44%|████▍     | 67/153 [01:34<02:01,  1.42s/it, loss=1.47e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.51e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  44%|████▍     | 68/153 [01:36<02:00,  1.42s/it, loss=1.47e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.51e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  44%|████▍     | 68/153 [01:36<02:00,  1.42s/it, loss=1.48e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.02e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  45%|████▌     | 69/153 [01:37<01:59,  1.42s/it, loss=1.48e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=3.02e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  45%|████▌     | 69/153 [01:37<01:59,  1.42s/it, loss=1.46e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.68e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  46%|████▌     | 70/153 [01:39<01:57,  1.42s/it, loss=1.46e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.68e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  46%|████▌     | 70/153 [01:39<01:57,  1.42s/it, loss=1.42e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.25e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  46%|████▋     | 71/153 [01:40<01:56,  1.42s/it, loss=1.42e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.25e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  46%|████▋     | 71/153 [01:40<01:56,  1.42s/it, loss=1.42e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.78e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  47%|████▋     | 72/153 [01:41<01:54,  1.42s/it, loss=1.42e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.78e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  47%|████▋     | 72/153 [01:41<01:54,  1.42s/it, loss=1.4e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.79e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000] Epoch 1:  48%|████▊     | 73/153 [01:43<01:53,  1.41s/it, loss=1.4e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.79e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  48%|████▊     | 73/153 [01:43<01:53,  1.41s/it, loss=1.38e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.03e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  48%|████▊     | 74/153 [01:45<01:52,  1.42s/it, loss=1.38e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.03e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  48%|████▊     | 74/153 [01:45<01:52,  1.42s/it, loss=1.36e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.67e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  49%|████▉     | 75/153 [01:46<01:50,  1.42s/it, loss=1.36e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.67e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  49%|████▉     | 75/153 [01:46<01:50,  1.42s/it, loss=9.14e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.7e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000] Epoch 1:  50%|████▉     | 76/153 [01:47<01:49,  1.42s/it, loss=9.14e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.7e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  50%|████▉     | 76/153 [01:47<01:49,  1.42s/it, loss=9.01e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.6e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  50%|█████     | 77/153 [01:48<01:47,  1.42s/it, loss=9.01e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.6e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  50%|█████     | 77/153 [01:48<01:47,  1.42s/it, loss=8.81e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.11e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  51%|█████     | 78/153 [01:50<01:46,  1.42s/it, loss=8.81e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.11e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  51%|█████     | 78/153 [01:50<01:46,  1.42s/it, loss=8.32e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.03e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  52%|█████▏    | 79/153 [01:51<01:44,  1.41s/it, loss=8.32e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.03e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  52%|█████▏    | 79/153 [01:51<01:44,  1.41s/it, loss=8.57e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.17e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  52%|█████▏    | 80/153 [01:53<01:43,  1.42s/it, loss=8.57e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.17e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  52%|█████▏    | 80/153 [01:53<01:43,  1.42s/it, loss=9.33e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.77e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  53%|█████▎    | 81/153 [01:54<01:41,  1.42s/it, loss=9.33e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.77e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  53%|█████▎    | 81/153 [01:54<01:41,  1.42s/it, loss=9.9e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.92e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000] Epoch 1:  54%|█████▎    | 82/153 [01:56<01:40,  1.42s/it, loss=9.9e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.92e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  54%|█████▎    | 82/153 [01:56<01:40,  1.42s/it, loss=9.5e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=9.92e+4, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  54%|█████▍    | 83/153 [01:57<01:39,  1.41s/it, loss=9.5e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=9.92e+4, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  54%|█████▍    | 83/153 [01:57<01:39,  1.41s/it, loss=9.55e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.14e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  55%|█████▍    | 84/153 [01:59<01:37,  1.42s/it, loss=9.55e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.14e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  55%|█████▍    | 84/153 [01:59<01:37,  1.42s/it, loss=9.42e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.4e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000] Epoch 1:  56%|█████▌    | 85/153 [02:00<01:36,  1.42s/it, loss=9.42e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.4e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  56%|█████▌    | 85/153 [02:00<01:36,  1.42s/it, loss=9.31e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.48e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  56%|█████▌    | 86/153 [02:01<01:34,  1.42s/it, loss=9.31e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.48e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  56%|█████▌    | 86/153 [02:01<01:34,  1.42s/it, loss=9.34e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.65e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  57%|█████▋    | 87/153 [02:03<01:33,  1.42s/it, loss=9.34e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.65e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  57%|█████▋    | 87/153 [02:03<01:33,  1.42s/it, loss=9.68e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.79e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  58%|█████▊    | 88/153 [02:05<01:32,  1.42s/it, loss=9.68e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.79e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  58%|█████▊    | 88/153 [02:05<01:32,  1.42s/it, loss=9.35e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  58%|█████▊    | 89/153 [02:06<01:30,  1.42s/it, loss=9.35e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  58%|█████▊    | 89/153 [02:06<01:30,  1.42s/it, loss=9.12e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.73e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  59%|█████▉    | 90/153 [02:07<01:29,  1.42s/it, loss=9.12e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.73e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  59%|█████▉    | 90/153 [02:07<01:29,  1.42s/it, loss=8.63e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.78e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  59%|█████▉    | 91/153 [02:08<01:27,  1.42s/it, loss=8.63e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.78e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  59%|█████▉    | 91/153 [02:08<01:27,  1.42s/it, loss=8.44e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.55e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  60%|██████    | 92/153 [02:10<01:26,  1.42s/it, loss=8.44e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.55e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  60%|██████    | 92/153 [02:10<01:26,  1.42s/it, loss=8.72e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.55e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  61%|██████    | 93/153 [02:11<01:25,  1.42s/it, loss=8.72e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.55e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  61%|██████    | 93/153 [02:11<01:25,  1.42s/it, loss=8.63e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.95e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  61%|██████▏   | 94/153 [02:13<01:23,  1.42s/it, loss=8.63e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.95e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  61%|██████▏   | 94/153 [02:13<01:23,  1.42s/it, loss=8.54e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.23e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  62%|██████▏   | 95/153 [02:14<01:22,  1.41s/it, loss=8.54e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.23e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  62%|██████▏   | 95/153 [02:14<01:22,  1.41s/it, loss=8.86e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.13e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  63%|██████▎   | 96/153 [02:15<01:20,  1.41s/it, loss=8.86e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.13e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  63%|██████▎   | 96/153 [02:15<01:20,  1.41s/it, loss=9.29e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.51e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  63%|██████▎   | 97/153 [02:17<01:19,  1.41s/it, loss=9.29e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.51e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  63%|██████▎   | 97/153 [02:17<01:19,  1.41s/it, loss=9.16e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.53e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  64%|██████▍   | 98/153 [02:18<01:17,  1.41s/it, loss=9.16e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.53e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  64%|██████▍   | 98/153 [02:18<01:17,  1.41s/it, loss=9.37e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.8e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000] Epoch 1:  65%|██████▍   | 99/153 [02:20<01:16,  1.41s/it, loss=9.37e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.8e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  65%|██████▍   | 99/153 [02:20<01:16,  1.41s/it, loss=9.25e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.47e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  65%|██████▌   | 100/153 [02:21<01:15,  1.42s/it, loss=9.25e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.47e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  65%|██████▌   | 100/153 [02:21<01:15,  1.42s/it, loss=9.14e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.58e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  66%|██████▌   | 101/153 [02:23<01:13,  1.42s/it, loss=9.14e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.58e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  66%|██████▌   | 101/153 [02:23<01:13,  1.42s/it, loss=8.91e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.09e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  67%|██████▋   | 102/153 [02:24<01:12,  1.42s/it, loss=8.91e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.09e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  67%|██████▋   | 102/153 [02:24<01:12,  1.42s/it, loss=8.75e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.23e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  67%|██████▋   | 103/153 [02:26<01:10,  1.42s/it, loss=8.75e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.23e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  67%|██████▋   | 103/153 [02:26<01:10,  1.42s/it, loss=8.66e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.76e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  68%|██████▊   | 104/153 [02:27<01:09,  1.42s/it, loss=8.66e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.76e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  68%|██████▊   | 104/153 [02:27<01:09,  1.42s/it, loss=9.01e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.93e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  69%|██████▊   | 105/153 [02:29<01:08,  1.42s/it, loss=9.01e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.93e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  69%|██████▊   | 105/153 [02:29<01:08,  1.42s/it, loss=8.93e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.97e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  69%|██████▉   | 106/153 [02:31<01:07,  1.43s/it, loss=8.93e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.97e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  69%|██████▉   | 106/153 [02:31<01:07,  1.43s/it, loss=8.65e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.95e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  70%|██████▉   | 107/153 [02:32<01:05,  1.43s/it, loss=8.65e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.95e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  70%|██████▉   | 107/153 [02:32<01:05,  1.43s/it, loss=8.94e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.11e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  71%|███████   | 108/153 [02:33<01:04,  1.43s/it, loss=8.94e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.11e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  71%|███████   | 108/153 [02:33<01:04,  1.43s/it, loss=9.14e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.2e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000] Epoch 1:  71%|███████   | 109/153 [02:35<01:02,  1.43s/it, loss=9.14e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.2e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  71%|███████   | 109/153 [02:35<01:02,  1.43s/it, loss=9.26e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.7e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  72%|███████▏  | 110/153 [02:37<01:01,  1.43s/it, loss=9.26e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.7e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  72%|███████▏  | 110/153 [02:37<01:01,  1.43s/it, loss=9.13e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.32e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  73%|███████▎  | 111/153 [02:38<00:59,  1.43s/it, loss=9.13e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.32e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  73%|███████▎  | 111/153 [02:38<00:59,  1.43s/it, loss=8.97e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.78e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  73%|███████▎  | 112/153 [02:39<00:58,  1.42s/it, loss=8.97e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.78e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  73%|███████▎  | 112/153 [02:39<00:58,  1.42s/it, loss=9.25e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.78e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  74%|███████▍  | 113/153 [02:40<00:56,  1.42s/it, loss=9.25e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.78e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  74%|███████▍  | 113/153 [02:40<00:56,  1.42s/it, loss=9.36e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.98e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  75%|███████▍  | 114/153 [02:41<00:55,  1.42s/it, loss=9.36e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.98e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  75%|███████▍  | 114/153 [02:41<00:55,  1.42s/it, loss=9.69e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.59e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  75%|███████▌  | 115/153 [02:43<00:54,  1.42s/it, loss=9.69e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.59e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  75%|███████▌  | 115/153 [02:43<00:54,  1.42s/it, loss=9.71e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.02e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  76%|███████▌  | 116/153 [02:44<00:52,  1.42s/it, loss=9.71e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.02e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  76%|███████▌  | 116/153 [02:44<00:52,  1.42s/it, loss=9.57e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.66e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  76%|███████▋  | 117/153 [02:46<00:51,  1.42s/it, loss=9.57e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.66e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  76%|███████▋  | 117/153 [02:46<00:51,  1.42s/it, loss=9.89e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.76e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  77%|███████▋  | 118/153 [02:48<00:49,  1.42s/it, loss=9.89e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.76e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  77%|███████▋  | 118/153 [02:48<00:49,  1.42s/it, loss=9.54e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.49e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  78%|███████▊  | 119/153 [02:49<00:48,  1.42s/it, loss=9.54e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.49e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  78%|███████▊  | 119/153 [02:49<00:48,  1.42s/it, loss=9.68e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.98e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  78%|███████▊  | 120/153 [02:50<00:46,  1.42s/it, loss=9.68e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.98e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  78%|███████▊  | 120/153 [02:50<00:46,  1.42s/it, loss=9.79e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.55e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  79%|███████▉  | 121/153 [02:52<00:45,  1.42s/it, loss=9.79e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.55e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  79%|███████▉  | 121/153 [02:52<00:45,  1.42s/it, loss=1.04e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.98e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  80%|███████▉  | 122/153 [02:52<00:43,  1.42s/it, loss=1.04e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.98e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1:  80%|███████▉  | 122/153 [02:52<00:43,  1.42s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/31 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/31 [00:00<?, ?it/s][A
Validation DataLoader 0:   3%|▎         | 1/31 [00:00<00:02, 10.20it/s][AEpoch 1:  80%|████████  | 123/153 [02:53<00:42,  1.41s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:   6%|▋         | 2/31 [00:00<00:13,  2.19it/s][AEpoch 1:  81%|████████  | 124/153 [02:54<00:40,  1.41s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  10%|▉         | 3/31 [00:01<00:15,  1.75it/s][AEpoch 1:  82%|████████▏ | 125/153 [02:55<00:39,  1.40s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  13%|█▎        | 4/31 [00:02<00:17,  1.57it/s][AEpoch 1:  82%|████████▏ | 126/153 [02:56<00:37,  1.40s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  16%|█▌        | 5/31 [00:03<00:19,  1.35it/s][AEpoch 1:  83%|████████▎ | 127/153 [02:57<00:36,  1.40s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  19%|█▉        | 6/31 [00:04<00:20,  1.22it/s][AEpoch 1:  84%|████████▎ | 128/153 [02:58<00:34,  1.39s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  23%|██▎       | 7/31 [00:06<00:21,  1.10it/s][AEpoch 1:  84%|████████▍ | 129/153 [02:59<00:33,  1.40s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  26%|██▌       | 8/31 [00:07<00:20,  1.12it/s][AEpoch 1:  85%|████████▍ | 130/153 [03:00<00:31,  1.39s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  29%|██▉       | 9/31 [00:07<00:19,  1.16it/s][AEpoch 1:  86%|████████▌ | 131/153 [03:01<00:30,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  32%|███▏      | 10/31 [00:09<00:19,  1.10it/s][AEpoch 1:  86%|████████▋ | 132/153 [03:02<00:29,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  35%|███▌      | 11/31 [00:10<00:18,  1.09it/s][AEpoch 1:  87%|████████▋ | 133/153 [03:03<00:27,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  39%|███▊      | 12/31 [00:11<00:18,  1.03it/s][AEpoch 1:  88%|████████▊ | 134/153 [03:05<00:26,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  42%|████▏     | 13/31 [00:12<00:17,  1.02it/s][AEpoch 1:  88%|████████▊ | 135/153 [03:06<00:24,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  45%|████▌     | 14/31 [00:14<00:17,  1.01s/it][AEpoch 1:  89%|████████▉ | 136/153 [03:07<00:23,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  48%|████▊     | 15/31 [00:15<00:16,  1.03s/it][AEpoch 1:  90%|████████▉ | 137/153 [03:09<00:22,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  52%|█████▏    | 16/31 [00:16<00:15,  1.05s/it][AEpoch 1:  90%|█████████ | 138/153 [03:10<00:20,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  55%|█████▍    | 17/31 [00:18<00:15,  1.08s/it][AEpoch 1:  91%|█████████ | 139/153 [03:12<00:19,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  58%|█████▊    | 18/31 [00:20<00:14,  1.12s/it][AEpoch 1:  92%|█████████▏| 140/153 [03:13<00:17,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  61%|██████▏   | 19/31 [00:21<00:13,  1.13s/it][AEpoch 1:  92%|█████████▏| 141/153 [03:15<00:16,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  65%|██████▍   | 20/31 [00:22<00:12,  1.13s/it][AEpoch 1:  93%|█████████▎| 142/153 [03:16<00:15,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  68%|██████▊   | 21/31 [00:23<00:11,  1.14s/it][AEpoch 1:  93%|█████████▎| 143/153 [03:17<00:13,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  71%|███████   | 22/31 [00:25<00:10,  1.14s/it][AEpoch 1:  94%|█████████▍| 144/153 [03:18<00:12,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  74%|███████▍  | 23/31 [00:26<00:09,  1.17s/it][AEpoch 1:  95%|█████████▍| 145/153 [03:20<00:11,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  77%|███████▋  | 24/31 [00:27<00:08,  1.16s/it][AEpoch 1:  95%|█████████▌| 146/153 [03:21<00:09,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  81%|████████  | 25/31 [00:29<00:06,  1.16s/it][AEpoch 1:  96%|█████████▌| 147/153 [03:22<00:08,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  84%|████████▍ | 26/31 [00:30<00:05,  1.18s/it][AEpoch 1:  97%|█████████▋| 148/153 [03:24<00:06,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  87%|████████▋ | 27/31 [00:31<00:04,  1.17s/it][AEpoch 1:  97%|█████████▋| 149/153 [03:25<00:05,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  90%|█████████ | 28/31 [00:33<00:03,  1.18s/it][AEpoch 1:  98%|█████████▊| 150/153 [03:26<00:04,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  94%|█████████▎| 29/31 [00:34<00:02,  1.19s/it][AEpoch 1:  99%|█████████▊| 151/153 [03:28<00:02,  1.38s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0:  97%|█████████▋| 30/31 [00:35<00:01,  1.18s/it][AEpoch 1:  99%|█████████▉| 152/153 [03:28<00:01,  1.37s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Validation DataLoader 0: 100%|██████████| 31/31 [00:35<00:00,  1.15s/it][AEpoch 1: 100%|██████████| 153/153 [03:29<00:00,  1.37s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]Epoch 1: 100%|██████████| 153/153 [03:29<00:00,  1.37s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=4.24e+5, discloss_epoch=0.000]
Epoch 1, global step 488: 'val/rec_loss' reached 1.08219 (best 1.08053), saving model to 'logs/2024-05-17T17-27-52_od_vae_test_1gpu/checkpoints/epoch=000001.ckpt' as top 3
                                                                        [AEpoch 1: 100%|██████████| 153/153 [03:29<00:00,  1.37s/it, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 1:   0%|          | 0/153 [00:00<?, ?it/s, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]          Epoch 2:   0%|          | 0/153 [00:00<?, ?it/s, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   1%|          | 1/153 [00:00<01:49,  1.39it/s, loss=1.02e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.37e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   1%|          | 1/153 [00:00<01:49,  1.39it/s, loss=1.01e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.83e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   1%|▏         | 2/153 [00:02<02:43,  1.09s/it, loss=1.01e+05, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.83e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   1%|▏         | 2/153 [00:02<02:44,  1.09s/it, loss=9.37e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.11e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   2%|▏         | 3/153 [00:03<03:07,  1.25s/it, loss=9.37e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.11e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   2%|▏         | 3/153 [00:03<03:07,  1.25s/it, loss=8.98e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.23e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   3%|▎         | 4/153 [00:05<03:20,  1.35s/it, loss=8.98e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.23e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   3%|▎         | 4/153 [00:05<03:20,  1.35s/it, loss=9.05e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.8e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000] Epoch 2:   3%|▎         | 5/153 [00:06<03:17,  1.34s/it, loss=9.05e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.8e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   3%|▎         | 5/153 [00:06<03:18,  1.34s/it, loss=8.48e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.61e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   4%|▍         | 6/153 [00:07<03:12,  1.31s/it, loss=8.48e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.61e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   4%|▍         | 6/153 [00:07<03:12,  1.31s/it, loss=8.4e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.33e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000] Epoch 2:   5%|▍         | 7/153 [00:09<03:13,  1.33s/it, loss=8.4e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.33e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   5%|▍         | 7/153 [00:09<03:13,  1.33s/it, loss=8.77e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.73e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   5%|▌         | 8/153 [00:10<03:14,  1.34s/it, loss=8.77e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.73e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   5%|▌         | 8/153 [00:10<03:14,  1.34s/it, loss=8.84e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.68e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   6%|▌         | 9/153 [00:12<03:12,  1.34s/it, loss=8.84e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.68e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   6%|▌         | 9/153 [00:12<03:12,  1.34s/it, loss=7.92e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.13e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   7%|▋         | 10/153 [00:13<03:09,  1.32s/it, loss=7.92e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.13e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   7%|▋         | 10/153 [00:13<03:09,  1.32s/it, loss=8.07e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.67e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   7%|▋         | 11/153 [00:14<03:07,  1.32s/it, loss=8.07e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.67e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   7%|▋         | 11/153 [00:14<03:07,  1.32s/it, loss=7.87e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.44e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   8%|▊         | 12/153 [00:16<03:11,  1.36s/it, loss=7.87e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.44e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   8%|▊         | 12/153 [00:16<03:11,  1.36s/it, loss=8.38e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.13e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   8%|▊         | 13/153 [00:17<03:07,  1.34s/it, loss=8.38e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=2.13e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   8%|▊         | 13/153 [00:17<03:07,  1.34s/it, loss=8.31e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.1e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000] Epoch 2:   9%|▉         | 14/153 [00:18<03:05,  1.34s/it, loss=8.31e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.1e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:   9%|▉         | 14/153 [00:18<03:05,  1.34s/it, loss=8.38e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.95e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:  10%|▉         | 15/153 [00:20<03:04,  1.34s/it, loss=8.38e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.95e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:  10%|▉         | 15/153 [00:20<03:04,  1.34s/it, loss=8.38e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.6e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000] Epoch 2:  10%|█         | 16/153 [00:21<03:03,  1.34s/it, loss=8.38e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.6e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:  10%|█         | 16/153 [00:21<03:03,  1.34s/it, loss=8.27e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.1e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:  11%|█         | 17/153 [00:22<03:00,  1.33s/it, loss=8.27e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.1e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:  11%|█         | 17/153 [00:22<03:00,  1.33s/it, loss=7.57e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.34e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:  12%|█▏        | 18/153 [00:23<02:58,  1.32s/it, loss=7.57e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.34e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:  12%|█▏        | 18/153 [00:23<02:58,  1.32s/it, loss=7.26e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.07e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:  12%|█▏        | 19/153 [00:25<02:57,  1.33s/it, loss=7.26e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.07e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epoch=2.08e+5, discloss_epoch=0.000]Epoch 2:  12%|█▏        | 19/153 [00:25<02:57,  1.33s/it, loss=7.57e+04, v_num=1gpu, dropout_prob_step=1.000, aeloss_step=1.74e+5, discloss_step=0.000, dropout_prob_epoch=1.000, aeloss_epochsrun: Job step aborted: Waiting up to 92 seconds for job step to finish.
slurmstepd: error: *** JOB 20823885 ON node209 CANCELLED AT 2024-05-17T17:36:12 ***
slurmstepd: error: *** STEP 20823885.0 ON node209 CANCELLED AT 2024-05-17T17:36:12 ***
bypassing sigterm
